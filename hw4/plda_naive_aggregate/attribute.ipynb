{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Naive Approach"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "test_data = pd.read_csv('goemotions_result/goemotions_result/test.tsv.predictions.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "data": {
      "text/plain": "      admiration  amusement         anger  annoyance  approval    caring  \\\n0       0.023641   0.012917  1.097456e-03   0.009892  0.034141  0.116517   \n1       0.933204   0.004205  1.246369e-03   0.003360  0.019069  0.000187   \n2       0.089634   0.001746  1.296259e-05   0.000133  0.041083  0.017735   \n3       0.013689   0.000143  2.241207e-07   0.000002  0.001616  0.000074   \n4       0.001300   0.000495  3.236829e-04   0.003689  0.010566  0.001229   \n...          ...        ...           ...        ...       ...       ...   \n5422    0.008883   0.000182  6.869349e-07   0.000007  0.004454  0.000267   \n5423    0.009865   0.001180  1.604202e-04   0.003505  0.447700  0.003912   \n5424    0.001092   0.000447  2.455627e-04   0.001439  0.003992  0.001233   \n5425    0.421594   0.003680  1.265485e-06   0.000013  0.016065  0.000376   \n5426    0.010065   0.139076  2.964907e-04   0.004983  0.020299  0.001697   \n\n         confusion  curiosity    desire  disappointment  ...      love  \\\n0     7.125542e-04   0.002107  0.004956    4.013909e-02  ...  0.059547   \n1     1.174788e-04   0.000395  0.000279    1.065288e-03  ...  0.008319   \n2     1.530337e-05   0.000205  0.010017    2.342856e-05  ...  0.006492   \n3     7.957947e-07   0.000004  0.000006    6.250209e-07  ...  0.000263   \n4     7.152921e-04   0.000668  0.000654    2.829553e-03  ...  0.000306   \n...            ...        ...       ...             ...  ...       ...   \n5422  2.024138e-06   0.000008  0.000013    2.090587e-06  ...  0.000402   \n5423  1.017455e-03   0.000855  0.000921    1.036496e-03  ...  0.000940   \n5424  1.187656e-04   0.000228  0.000846    5.014784e-04  ...  0.001954   \n5425  1.481699e-06   0.000012  0.000134    5.308465e-06  ...  0.014122   \n5426  6.845386e-04   0.002512  0.013056    2.162143e-03  ...  0.011427   \n\n       nervousness  optimism     pride  realization    relief       remorse  \\\n0     1.720527e-04  0.047342  0.000247     0.024137  0.002331  5.658123e-02   \n1     5.115182e-06  0.002083  0.000080     0.001334  0.000099  4.700262e-06   \n2     3.465869e-07  0.668925  0.000108     0.000885  0.001137  3.121946e-06   \n3     5.788415e-09  0.000343  0.000007     0.000070  0.000047  2.233747e-07   \n4     9.647095e-06  0.002331  0.000030     0.013309  0.000129  1.455933e-05   \n...            ...       ...       ...          ...       ...           ...   \n5422  2.165691e-08  0.000678  0.000014     0.000249  0.000092  1.055466e-06   \n5423  5.068461e-06  0.009365  0.000110     0.070052  0.000448  1.020387e-05   \n5424  1.391325e-06  0.001013  0.000023     0.001338  0.000073  1.211944e-06   \n5425  1.478067e-08  0.002769  0.000091     0.000386  0.000420  4.014390e-07   \n5426  3.719944e-06  0.010666  0.000144     0.018008  0.000740  1.323852e-05   \n\n       sadness  surprise   neutral  \n0     0.402959  0.001536  0.056852  \n1     0.000333  0.001237  0.007475  \n2     0.000021  0.000200  0.007555  \n3     0.000001  0.000011  0.000101  \n4     0.001095  0.000592  0.957267  \n...        ...       ...       ...  \n5422  0.000005  0.000018  0.000302  \n5423  0.000151  0.000941  0.440604  \n5424  0.000139  0.000155  0.983130  \n5425  0.000004  0.000109  0.000666  \n5426  0.000665  0.004921  0.677519  \n\n[5427 rows x 28 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>admiration</th>\n      <th>amusement</th>\n      <th>anger</th>\n      <th>annoyance</th>\n      <th>approval</th>\n      <th>caring</th>\n      <th>confusion</th>\n      <th>curiosity</th>\n      <th>desire</th>\n      <th>disappointment</th>\n      <th>...</th>\n      <th>love</th>\n      <th>nervousness</th>\n      <th>optimism</th>\n      <th>pride</th>\n      <th>realization</th>\n      <th>relief</th>\n      <th>remorse</th>\n      <th>sadness</th>\n      <th>surprise</th>\n      <th>neutral</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.023641</td>\n      <td>0.012917</td>\n      <td>1.097456e-03</td>\n      <td>0.009892</td>\n      <td>0.034141</td>\n      <td>0.116517</td>\n      <td>7.125542e-04</td>\n      <td>0.002107</td>\n      <td>0.004956</td>\n      <td>4.013909e-02</td>\n      <td>...</td>\n      <td>0.059547</td>\n      <td>1.720527e-04</td>\n      <td>0.047342</td>\n      <td>0.000247</td>\n      <td>0.024137</td>\n      <td>0.002331</td>\n      <td>5.658123e-02</td>\n      <td>0.402959</td>\n      <td>0.001536</td>\n      <td>0.056852</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.933204</td>\n      <td>0.004205</td>\n      <td>1.246369e-03</td>\n      <td>0.003360</td>\n      <td>0.019069</td>\n      <td>0.000187</td>\n      <td>1.174788e-04</td>\n      <td>0.000395</td>\n      <td>0.000279</td>\n      <td>1.065288e-03</td>\n      <td>...</td>\n      <td>0.008319</td>\n      <td>5.115182e-06</td>\n      <td>0.002083</td>\n      <td>0.000080</td>\n      <td>0.001334</td>\n      <td>0.000099</td>\n      <td>4.700262e-06</td>\n      <td>0.000333</td>\n      <td>0.001237</td>\n      <td>0.007475</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.089634</td>\n      <td>0.001746</td>\n      <td>1.296259e-05</td>\n      <td>0.000133</td>\n      <td>0.041083</td>\n      <td>0.017735</td>\n      <td>1.530337e-05</td>\n      <td>0.000205</td>\n      <td>0.010017</td>\n      <td>2.342856e-05</td>\n      <td>...</td>\n      <td>0.006492</td>\n      <td>3.465869e-07</td>\n      <td>0.668925</td>\n      <td>0.000108</td>\n      <td>0.000885</td>\n      <td>0.001137</td>\n      <td>3.121946e-06</td>\n      <td>0.000021</td>\n      <td>0.000200</td>\n      <td>0.007555</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.013689</td>\n      <td>0.000143</td>\n      <td>2.241207e-07</td>\n      <td>0.000002</td>\n      <td>0.001616</td>\n      <td>0.000074</td>\n      <td>7.957947e-07</td>\n      <td>0.000004</td>\n      <td>0.000006</td>\n      <td>6.250209e-07</td>\n      <td>...</td>\n      <td>0.000263</td>\n      <td>5.788415e-09</td>\n      <td>0.000343</td>\n      <td>0.000007</td>\n      <td>0.000070</td>\n      <td>0.000047</td>\n      <td>2.233747e-07</td>\n      <td>0.000001</td>\n      <td>0.000011</td>\n      <td>0.000101</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.001300</td>\n      <td>0.000495</td>\n      <td>3.236829e-04</td>\n      <td>0.003689</td>\n      <td>0.010566</td>\n      <td>0.001229</td>\n      <td>7.152921e-04</td>\n      <td>0.000668</td>\n      <td>0.000654</td>\n      <td>2.829553e-03</td>\n      <td>...</td>\n      <td>0.000306</td>\n      <td>9.647095e-06</td>\n      <td>0.002331</td>\n      <td>0.000030</td>\n      <td>0.013309</td>\n      <td>0.000129</td>\n      <td>1.455933e-05</td>\n      <td>0.001095</td>\n      <td>0.000592</td>\n      <td>0.957267</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>5422</th>\n      <td>0.008883</td>\n      <td>0.000182</td>\n      <td>6.869349e-07</td>\n      <td>0.000007</td>\n      <td>0.004454</td>\n      <td>0.000267</td>\n      <td>2.024138e-06</td>\n      <td>0.000008</td>\n      <td>0.000013</td>\n      <td>2.090587e-06</td>\n      <td>...</td>\n      <td>0.000402</td>\n      <td>2.165691e-08</td>\n      <td>0.000678</td>\n      <td>0.000014</td>\n      <td>0.000249</td>\n      <td>0.000092</td>\n      <td>1.055466e-06</td>\n      <td>0.000005</td>\n      <td>0.000018</td>\n      <td>0.000302</td>\n    </tr>\n    <tr>\n      <th>5423</th>\n      <td>0.009865</td>\n      <td>0.001180</td>\n      <td>1.604202e-04</td>\n      <td>0.003505</td>\n      <td>0.447700</td>\n      <td>0.003912</td>\n      <td>1.017455e-03</td>\n      <td>0.000855</td>\n      <td>0.000921</td>\n      <td>1.036496e-03</td>\n      <td>...</td>\n      <td>0.000940</td>\n      <td>5.068461e-06</td>\n      <td>0.009365</td>\n      <td>0.000110</td>\n      <td>0.070052</td>\n      <td>0.000448</td>\n      <td>1.020387e-05</td>\n      <td>0.000151</td>\n      <td>0.000941</td>\n      <td>0.440604</td>\n    </tr>\n    <tr>\n      <th>5424</th>\n      <td>0.001092</td>\n      <td>0.000447</td>\n      <td>2.455627e-04</td>\n      <td>0.001439</td>\n      <td>0.003992</td>\n      <td>0.001233</td>\n      <td>1.187656e-04</td>\n      <td>0.000228</td>\n      <td>0.000846</td>\n      <td>5.014784e-04</td>\n      <td>...</td>\n      <td>0.001954</td>\n      <td>1.391325e-06</td>\n      <td>0.001013</td>\n      <td>0.000023</td>\n      <td>0.001338</td>\n      <td>0.000073</td>\n      <td>1.211944e-06</td>\n      <td>0.000139</td>\n      <td>0.000155</td>\n      <td>0.983130</td>\n    </tr>\n    <tr>\n      <th>5425</th>\n      <td>0.421594</td>\n      <td>0.003680</td>\n      <td>1.265485e-06</td>\n      <td>0.000013</td>\n      <td>0.016065</td>\n      <td>0.000376</td>\n      <td>1.481699e-06</td>\n      <td>0.000012</td>\n      <td>0.000134</td>\n      <td>5.308465e-06</td>\n      <td>...</td>\n      <td>0.014122</td>\n      <td>1.478067e-08</td>\n      <td>0.002769</td>\n      <td>0.000091</td>\n      <td>0.000386</td>\n      <td>0.000420</td>\n      <td>4.014390e-07</td>\n      <td>0.000004</td>\n      <td>0.000109</td>\n      <td>0.000666</td>\n    </tr>\n    <tr>\n      <th>5426</th>\n      <td>0.010065</td>\n      <td>0.139076</td>\n      <td>2.964907e-04</td>\n      <td>0.004983</td>\n      <td>0.020299</td>\n      <td>0.001697</td>\n      <td>6.845386e-04</td>\n      <td>0.002512</td>\n      <td>0.013056</td>\n      <td>2.162143e-03</td>\n      <td>...</td>\n      <td>0.011427</td>\n      <td>3.719944e-06</td>\n      <td>0.010666</td>\n      <td>0.000144</td>\n      <td>0.018008</td>\n      <td>0.000740</td>\n      <td>1.323852e-05</td>\n      <td>0.000665</td>\n      <td>0.004921</td>\n      <td>0.677519</td>\n    </tr>\n  </tbody>\n</table>\n<p>5427 rows × 28 columns</p>\n</div>"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "data": {
      "text/plain": "5427"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('data/test_ekman.tsv','r',encoding= 'utf-8') as f:\n",
    "    all_lines = f.readlines()\n",
    "all_text = []\n",
    "for i in all_lines:\n",
    "    all_text.append(i.split('\\t')[0])\n",
    "len(all_text)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "data_arr = test_data.to_numpy()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "import json\n",
    "with open('data/ekman_mapping.json') as f:\n",
    "    mapping_dict = json.loads(f.read())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "all_sent = \"admiration\tamusement\tanger\tannoyance\tapproval\tcaring\tconfusion\tcuriosity\tdesire\tdisappointment\tdisapproval\tdisgust\tembarrassment\texcitement\tfear\tgratitude\tgrief\tjoy\tlove\tnervousness\toptimism\tpride\trealization\trelief\tremorse\tsadness\tsurprise\tneutral\".split('\\t')\n",
    "all_sent_dict = {key:val for val,key in enumerate(all_sent)}\n",
    "ekman = ['anger', 'disgust', 'fear', 'joy', 'neutral', 'sadness', 'surprise']\n",
    "ekman_map = {key:val for val,key in enumerate(ekman)}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "new_mapping ={}\n",
    "for i in mapping_dict:\n",
    "    sub_emotions = mapping_dict[i]\n",
    "    emotion_idx = ekman_map[i]\n",
    "    for k in sub_emotions:\n",
    "        new_mapping[all_sent_dict[k]] = emotion_idx\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "all_prob = []\n",
    "for i in data_arr:\n",
    "    new_prob = [[],[],[],[],[],[],[]]\n",
    "    for k in range(len(i)):\n",
    "        new_prob[new_mapping[k]].append(i[k])\n",
    "    for k in range(7):\n",
    "        new_prob[k] = np.array(new_prob[k])\n",
    "    all_prob.append(new_prob)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "new_all = []\n",
    "for i in all_prob:\n",
    "    new_prob = []\n",
    "    for k in i:\n",
    "        tmp = 1-np.product(1-k)\n",
    "        new_prob.append(tmp)\n",
    "    new_all.append(np.array(new_prob))\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [],
   "source": [
    "with open('test_out/test_prod.tsv','w',encoding= 'utf-8') as f:\n",
    "    f.write('anger\\tdisgust\\tfear\\tjoy\\tneutral\\tsadness\\tsurprise\\n')\n",
    "    for i in range(len(all_text)):\n",
    "        probs = new_all[i]\n",
    "        idx = np.argsort(-probs)\n",
    "        for k in range(7):\n",
    "            # if k in idx[:2]:\n",
    "            #     f.write('%.4f'%probs[k])\n",
    "            # else:\n",
    "            #     f.write('0.0000')\n",
    "            f.write('%.4f'%probs[k])\n",
    "            f.write('\\t')\n",
    "        f.write(('\\n'))\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# PLDA Approach"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "with open('data/train_ekman.tsv','r',encoding='utf-8') as f:\n",
    "    all_lines = f.readlines()\n",
    "train_lab = []"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "for i in all_lines:\n",
    "    _,labels, tst = i.split('\\t')\n",
    "    labels = labels.split(',')\n",
    "    train_lab.append(int(labels[0]))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "with open('data/test_ekman.tsv','r',encoding='utf-8') as f:\n",
    "    all_lines = f.readlines()\n",
    "test_lab = []\n",
    "for i in all_lines:\n",
    "    _,labels, tst = i.split('\\t')\n",
    "    labels = labels.split(',')\n",
    "    test_lab.append(int(labels[0]))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "(5427, 43410)"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_lab),len(train_lab)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "train_X = np.loadtxt('ckpt_test/train.tsv.text_features.txt',delimiter=',')\n",
    "test_X = np.loadtxt('ckpt_test/test.tsv.text_features.txt',delimiter=',')\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "import plda\n",
    "def softmax(a):\n",
    "    tmp = np.exp(a)\n",
    "    return tmp / np.sum(tmp)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "train_lab = np.array(train_lab)\n",
    "overfit_classifier = plda.Classifier()\n",
    "overfit_classifier.fit_model(train_X, train_lab)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "pred = overfit_classifier.predict(test_X)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "with open('test_out/plda.tsv','w',encoding='utf-8') as f:\n",
    "    f.write('anger\tdisgust\tfear\tjoy\tneutral\tsadness\tsurprise\\n')\n",
    "    for i in pred[1]:\n",
    "        softm = softmax(i)\n",
    "        for k in softm:\n",
    "            f.write('%.4f'%k)\n",
    "            f.write('\\t')\n",
    "        f.write('\\n')\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "def softmax(a):\n",
    "    tmp = np.exp(a)\n",
    "    return tmp/np.sum(tmp)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "data": {
      "text/plain": "array([2.04278640e-16, 2.92565901e-47, 6.35820675e-59, 1.32252941e-16,\n       8.44996375e-15, 1.00000000e+00, 1.10461023e-15])"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax(pred[1][0])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
