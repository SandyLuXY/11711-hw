Proceedings O
of O
the O
59th O
Annual O
Meeting O
of O
the O
Association O
for O
Computational O
Linguistics O
and O
the O
11th O
International O
Joint O
Conference O
on O
Natural O
Language O
Processing O
, O
pages O
3682–3692 O
August O
1–6 O
, O
2021 O
. O

© O
2021 O
Association O
for O
Computational O
Linguistics3682MPC O
- O
BERT B-MethodName
: O
A O
Pre O
- O
Trained O
Language O
Model O
for O
Multi O
- O
Party O
Conversation O
Understanding O
Jia O
- O
Chen O
Gu1 O
, O
Chongyang O
Tao2 O
, O
Zhen O
- O
Hua O
Ling1 O
, O
Can O
Xu2 O
, O
Xiubo O
Geng2 O
, O
Daxin O
Jiang2y O
1National O
Engineering O
Laboratory O
for O
Speech O
and O
Language O
Information O
Processing O
, O
University O
of O
Science O
and O
Technology O
of O
China O
, O
Hefei O
, O
China O
2Microsoft O
, O
Beijing O
, O
China O
gujc@mail.ustc.edu.cn O
, O
zhling@ustc.edu.cn O
, O
fchotao O
, O
caxu O
, O
xigeng O
, O
djiang O
g@microsoft.com O
Abstract O
Recently O
, O
various O
neural O
models O
for O
multiparty O
conversation O
( O
MPC O
) O
have O
achieved O
impressive O
improvements O
on O
a O
variety O
of O
tasks O
such O
as O
addressee O
recognition O
, O
speaker O
identiﬁcation O
and O
response O
prediction O
. O

However O
, O
these O
existing O
methods O
on O
MPC O
usually O
represent O
interlocutors O
and O
utterances O
individually O
and O
ignore O
the O
inherent O
complicated O
structure O
in O
MPC O
which O
may O
provide O
crucial O
interlocutor O
and O
utterance O
semantics O
and O
would O
enhance O
the O
conversation O
understanding O
process O
. O

To O
this O
end O
, O
we O
present O
MPC B-MethodName
- I-MethodName
BERT I-MethodName
, O
a O
pre O
- O
trained O
model O
for O
MPC O
understanding O
that O
considers O
learning O
who O
says O
what O
towhom O
in O
a O
uniﬁed O
model O
with O
several O
elaborated O
self O
- O
supervised O
tasks O
. O

Particularly O
, O
these O
tasks O
can O
be O
generally O
categorized O
into O
( O
1 O
) O
interlocutor O
structure O
modeling O
including O
reply O
- O
to O
utterance O
recognition O
, O
identical O
speaker O
searching O
and O
pointer O
consistency O
distinction O
, O
and O
( O
2 O
) O
utterance O
semantics O
modeling O
including O
masked O
shared O
utterance O
restoration O
and O
shared O
node O
detection O
. O

We O
evaluate O
MPCBERT B-MethodName
on O
three O
downstream O
tasks O
including O
addressee O
recognition O
, O
speaker O
identiﬁcation O
and O
response O
selection O
. O

Experimental O
results O
show O
that O
MPC B-MethodName
- I-MethodName
BERT I-MethodName
outperforms O
previous O
methods O
by O
large O
margins O
and O
achieves O
new O
state O
- O
of O
- O
the O
- O
art O
performance O
on O
all O
three O
downstream O
tasks O
at O
two O
benchmarks O
. O

1 O
Introduction O
Building O
a O
conversational O
agent O
with O
intelligence O
has O
drawn O
signiﬁcant O
attention O
from O
both O
academia O
and O
industry O
. O

Most O
of O
existing O
methods O
have O
studied O
understanding O
conversations O
between O
two O
participants O
, O
aiming O
to O
return O
an O
appropriate O
response O
either O
in O
a O
generation O
- O
based O
( O
Shang O
et O
al O
. O
, O
Work O
done O
during O
the O
internship O
at O
Microsoft O
. O

yCorresponding O
author O
. O

Speaker O
Utterance O
Addressee O
I.1How O
can O
I O
setup O
if O
I O
want O
add O
new O
- O
server O
at O
xchat O
? O

I.2From O
places O
, O
network O
servers O
, O
work O
I.1 O
group O
, O
his O
computer O
, O
and O
then O
I O
clicked O
on O
the O
shared O
folder O
. O

I.3 O
It O
did O
not O
allow O
you O
to O
see O
the O
ﬁles O
? O

I.2 O
I.2It O
prompts O
for O
authentication O
and O
I O
I.3 O
do O
n’t O
know O
what O
to O
put O
. O

I O
tried O
guest O
with O
no O
password O
. O

I.4 O
Put O
proper O
authentication O
in O
, O
then O
? O

I.2 O
I.3 O
I O
think O
you O
had O
kde O
on O
suse O
? O

I.2 O
Table O
1 O
: O
An O
MPC O
example O
in O
Ubuntu O
IRC O
channel O
. O

Here O
, O
“ O
I. O
” O
is O
the O
abbreviation O
of O
“ O
interlocutor O
” O
. O
2015 O
; O
Serban O
et O
al O
. O
, O
2016 O
, O
2017 O
; O
Zhang O
et O
al O
. O
, O
2018b O
, O
2020 O
) O
or O
retrieval O
- O
based O
manner O
( O
Lowe O
et O
al O
. O
, O
2015 O
; O
Wu O
et O
al O
. O
, O
2017 O
; O
Zhou O
et O

al O
. O
, O
2018 O
; O
Tao O
et O
al O
. O
, O
2019a O
, O
b O
; O
Gu O
et O
al O
. O
, O
2019a O
, O
b O
, O
2020 O
) O
. O

Recently O
, O
researchers O
have O
paid O
more O
attention O
to O
a O
more O
practical O
and O
challenging O
scenario O
involving O
more O
than O
two O
participants O
, O
which O
is O
well O
known O
as O
multiparty O
conversation O
( O
MPC O
) O
( O
Ouchi O
and O
Tsuboi O
, O
2016 O
; O
Zhang O
et O
al O
. O
, O
2018a O
; O
Le O
et O
al O
. O
, O
2019 O
; O
Hu O
et O
al O
. O
, O
2019 O
) O
. O

Table O
1 O
shows O
an O
MPC O
example O
in O
the O
Ubuntu O
Internet O
Relay O
Chat O
( O
IRC O
) O
channel O
, O
which O
is O
composed O
of O
a O
sequence O
of O
( O
speaker O
, O
utterance O
, O
addressee O
) O
triples O
. O

In O
addition O
to O
returning O
an O
appropriate O
response O
, O
predicting O
who O
will O
be O
the O
next O
speaker O
( O
Meng O
et O
al O
. O
, O
2018 O
) O
and O
who O
is O
the O
addressee O
of O
an O
utterance O
( O
Ouchi O
and O
Tsuboi O
, O
2016 O
; O
Zhang O
et O
al O
. O
, O
2018a O
; O
Le O
et O
al O
. O
, O
2019 O
) O
are O
unique O
and O
important O
issues O
in O
MPC O
. O

An O
instance O
of O
MPC O
always O
contains O
complicated O
interactions O
between O
interlocutors O
, O
between O
utterances O
and O
between O
an O
interlocutor O
and O
an O
utterance O
. O

Therefore O
, O
it O
is O
challenging O
to O
model O
the O
conversation O
ﬂow O
and O
fully O
understand O
the O
dialogue O
content O
. O

Existing O
studies O
on O
MPC O
learn O
the O
representations O
of O
interlocutors O
and O
utterances O
with O
neural O
networks O
, O
and O
their O
representation3683spaces O
are O
either O
separate O
( O
Ouchi O
and O
Tsuboi O
, O
2016 O
) O
or O
interactive O
( O
Zhang O
et O
al O
. O
, O
2018a O
) O
. O

However O
, O
the O
semantics O
contained O
in O
the O
interlocutor O
and O
utterance O
representations O
may O
not O
be O
effectively O
captured O
as O
they O
are O
from O
two O
different O
representation O
spaces O
. O

Recently O
, O
to O
take O
advantage O
of O
the O
breakthrough O
in O
pre O
- O
training O
language O
models O
( O
PLMs O
) O
for O
natural O
language O
understanding O
, O
some O
studies O
proposed O
to O
integrate O
the O
speaker O
( O
Gu O
et O
al O
. O
, O
2020 O
) O
or O
topic O
( O
Wang O
et O
al O
. O
, O
2020 O
) O
information O
into O
PLMs O
. O

Despite O
of O
the O
performance O
improvement O
on O
response O
selection O
, O
these O
models O
still O
overlook O
the O
inherent O
relationships O
between O
utterances O
and O
interlocutors O
, O
such O
as O
“ O
address O
- O
to O
” O
. O

Furthermore O
, O
most O
existing O
studies O
design O
models O
for O
each O
individual O
task O
in O
MPC O
( O
e.g. O
, O
addressee O
recognition O
, O
speaker O
identiﬁcation O
and O
response O
prediction O
) O
separately O
. O

Intuitively O
, O
these O
tasks O
are O
complementary O
among O
each O
other O
. O

Making O
use O
of O
these O
tasks O
simultaneously O
may O
produce O
better O
contextualized O
representations O
of O
interlocutors O
and O
utterances O
, O
and O
would O
enhance O
the O
conversation O
understanding O
, O
but O
is O
neglected O
in O
previous O
studies O
. O

On O
account O
of O
above O
issues O
, O
we O
propose O
MPCBERT B-MethodName
which O
jointly O
learns O
who O
says O
what O
towhom O
in O
MPC O
by O
designing O
self O
- O
supervised O
tasks O
for O
PLMs O
, O
so O
as O
to O
improve O
the O
ability O
of O
PLMs O
on O
MPC O
understanding O
. O

Speciﬁcally O
, O
the O
ﬁve O
designed O
tasks O
includes O
reply O
- O
to O
utterance O
recognition O
, O
identical O
speaker O
searching O
, O
pointer O
consistency O
distinction O
, O
masked O
shared O
utterance O
restoration O
and O
shared O
node O
detection O
. O

The O
ﬁrst O
three O
tasks O
are O
designed O
to O
model O
the O
interlocutor O
structure O
in O
MPC O
in O
a O
semantics O
- O
to O
- O
structure O
manner O
. O

In O
the O
output O
of O
MPC B-MethodName
- I-MethodName
BERT I-MethodName
, O
an O
interlocutor O
is O
described O
through O
the O
encoded O
representations O
of O
the O
utterances O
it O
says O
. O

Thus O
, O
the O
representations O
of O
utterance O
semantics O
are O
utilized O
to O
construct O
the O
conversation O
structure O
in O
these O
three O
tasks O
. O

On O
the O
other O
hand O
, O
the O
last O
two O
tasks O
are O
designed O
to O
model O
the O
utterance O
semantics O
in O
a O
structure O
- O
to O
- O
semantics O
manner O
. O

Intuitively O
, O
the O
conversation O
structure O
inﬂuences O
the O
information O
ﬂow O
in O
MPC O
. O

Thus O
, O
the O
structure O
information O
can O
also O
be O
used O
to O
strengthen O
the O
representations O
of O
utterance O
semantics O
in O
return O
. O

In O
general O
, O
these O
ﬁve O
self O
- O
supervised O
tasks O
are O
employed O
to O
jointly O
train O
the O
MPC B-MethodName
- I-MethodName
BERT I-MethodName
in O
a O
multi O
- O
task O
learning O
framework O
, O
which O
helps O
the O
model O
to O
learn O
the O
complementary O
information O
among O
interlocutors O
and O
utterances O
, O
and O
that O
between O
structure O
and O
semantics O
. O

By O
this O
means O
, O
MPC B-MethodName
- I-MethodName
BERT I-MethodName
can O
produce O
better O
interlocutor O
and O
utterance O
representations O
which O
can O
be O
effectively O
generalized O
to O
multiple O
downstream O
tasks O
of O
MPC O
. O

To O
measure O
the O
effectiveness O
of O
these O
selfsupervised O
tasks O
and O
to O
test O
the O
generalization O
ability O
of O
MPC B-MethodName
- I-MethodName
BERT I-MethodName
, O
we O
evaluate O
it O
on O
three O
downstream O
tasks O
including O
addressee B-TaskName
recognition I-TaskName
, O
speaker B-TaskName
identiﬁcation I-TaskName
and O
response B-TaskName
selection I-TaskName
, O
which O
are O
three O
core O
research O
issues O
of O
MPC O
. O

Two O
benchmarks O
based O
on O
Ubuntu O
IRC O
channel O
are O
employed O
for O
evaluation O
. O

One O
was O
released O
by O
Hu O
et O
al O
. O

( O
2019 O
) O
. O

The O
other O
was O
released O
by O
Ouchi O
and O
Tsuboi O
( O
2016 O
) O
and O
has O
three O
experimental O
settings O
according O
to O
session O
lengths O
. O

Experimental O
results O
show O
that O
MPC B-MethodName
- I-MethodName
BERT I-MethodName
outperforms O
the O
current O
state O
- O
of O
- O
the O
- O
art O
models O
by O
margins O
of O
3.51 O
% O
, O
2.86 O
% O
, O
3.28 O
% O
and O
5.36 O
% O
on O
the O
test O
sets O
of O
these O
two O
benchmarks O
respectively O
in O
terms O
of O
the O
session O
accuracy O
of O
addressee O
recognition O
, O
by O
margins O
of O
7.66 O
% O
, O
2.60 O
% O
, O
3.38 O
% O
and O
4.24 O
% O
respectively O
in O
terms O
of O
the O
utterance O
precision O
of O
speaker O
identiﬁcation O
, O
and O
by O
margins O
of O
3.82 O
% O
, O
2.71 O
% O
, O
2.55 O
% O
and O
3.22 O
% O
respectively O
in O
terms O
of O
the O
response O
recall O
of O
response O
selection O
. O

In O
summary O
, O
our O
contributions O
in O
this O
paper O
are O
three O
- O
fold O
: O
( O
1 O
) O
MPC B-MethodName
- I-MethodName
BERT I-MethodName
, O
a O
PLM O
for O
MPC O
understanding O
, O
is O
proposed O
by O
designing O
ﬁve O
selfsupervised O
tasks O
based O
on O
the O
interactions O
among O
utterances O
and O
interlocutors O
. O

( O
2 O
) O
Three O
downstream O
tasks O
are O
employed O
to O
comprehensively O
evaluate O
the O
effectiveness O
of O
our O
designed O
self O
- O
supervised O
tasks O
and O
the O
generalization O
ability O
of O
MPC B-MethodName
- I-MethodName
BERT I-MethodName
. O

( O
3 O
) O
Our O
proposed O
MPC B-MethodName
- I-MethodName
BERT I-MethodName
achieves O
new O
state O
- O
ofthe O
- O
art O
performance O
on O
all O
three O
downstream O
tasks O
at O
two O
benchmarks O
. O

2 O
Related O
Work O
Existing O
methods O
on O
building O
dialogue O
systems O
can O
be O
generally O
categorized O
into O
studying O
twoparty O
conversations O
and O
multi O
- O
party O
conversations O
( O
MPC O
) O
. O

In O
this O
paper O
, O
we O
study O
MPC O
. O

In O
addition O
to O
predicting O
utterances O
, O
identifying O
the O
speaker O
and O
recognizing O
the O
addressee O
of O
an O
utterance O
are O
also O
important O
tasks O
for O
MPC O
. O

Ouchi O
and O
Tsuboi O
( O
2016 O
) O
ﬁrst O
proposed O
the O
task O
of O
addressee O
and O
response O
selection O
and O
created O
an O
MPC O
corpus O
for O
studying O
this O
task O
. O

Zhang O
et O
al O
. O

( O
2018a O
) O
proposed O
SI B-MethodName
- I-MethodName
RNN I-MethodName
, O
which O
updated O
speaker O
embeddings O
role O
- O
sensitively O
for O
addressee O
and O
response O
selection O
. O

Meng O
et O

al O
. O
( O
2018 O
) O
proposed O
a O
task O
of O
speaker O
classiﬁcation O
as O
a O
surrogate O
task O
for O
speaker O
modeling O
. O

Le O
et O
al.3684(2019 O
) O
proposed O
a O
who B-MethodName
- I-MethodName
to I-MethodName
- I-MethodName
whom I-MethodName
( O
W2W B-MethodName
) O
model O
to O
recognize O
the O
addressees O
of O
all O
utterances O
. O

Hu O
et O
al O
. O

( O
2019 O
) O
proposed O
a O
graph B-MethodName
- I-MethodName
structured I-MethodName
network I-MethodName
( O
GSN B-MethodName
) O
to O
model O
the O
graphical O
information O
ﬂow O
for O
response O
generation O
. O

Wang O
et O
al O
. O

( O
2020 O
) O
proposed O
to O
track O
the O
dynamic O
topic O
for O
response O
selection O
. O

Generally O
speaking O
, O
previous O
studies O
on O
MPC O
can O
not O
unify O
the O
representations O
of O
interlocutors O
and O
utterances O
effectively O
. O

Also O
, O
they O
are O
limited O
to O
each O
individual O
task O
, O
ignoring O
the O
complementary O
information O
among O
different O
tasks O
. O

To O
the O
best O
of O
our O
knowledge O
, O
this O
paper O
makes O
the O
ﬁrst O
attempt O
to O
design O
various O
self O
- O
supervised O
tasks O
for O
building O
PLMs O
aiming O
at O
MPC O
understanding O
, O
and O
to O
evaluate O
the O
performance O
of O
PLMs O
on O
three O
downstream O
tasks O
as O
comprehensively O
as O
possible O
. O

3 O
MPC B-MethodName
- I-MethodName
BERT I-MethodName
and O
Self O
- O
Supervised O
Tasks O
An O
MPC O
instance O
is O
composed O
of O
a O
sequence O
of O
( O
speaker O
, O
utterance O
, O
addressee O
) O
triples O
, O
denoted O
asf(sn O
; O
un O
; O
an)gN O
n=1 O
, O
where O
Nis O
the O
number O
of O
turns O
in O
the O
conversation O
. O

Our O
goal O
is O
to O
build O
a O
pre O
- O
trained O
language O
model O
for O
universal O
MPC O
understanding O
. O

Given O
a O
conversation O
, O
this O
model O
is O
expected O
to O
produce O
embedding O
vectors O
for O
all O
utterances O
which O
contain O
not O
only O
the O
semantic O
information O
of O
each O
utterance O
, O
but O
also O
the O
speaker O
and O
addressee O
structure O
of O
the O
whole O
conversation O
. O

Thus O
, O
it O
can O
be O
effectively O
adapted O
to O
various O
downstream O
tasks O
by O
ﬁne O
- O
tuning O
model O
parameters O
. O

3.1 O
Model O
Overview O
In O
this O
paper O
, O
BERT B-MethodName
( O
Devlin O
et O
al O
. O
, O
2019 O
) O
is O
chosen O
as O
the O
backbone O
of O
our O
PLM O
for O
MPC O
. O

Thus O
, O
we O
name O
it O
MPC B-MethodName
- I-MethodName
BERT I-MethodName
. O

It O
is O
worth O
noting O
that O
our O
proposed O
self O
- O
supervised O
tasks O
for O
training O
MPCBERT B-MethodName
can O
also O
be O
applied O
to O
other O
types O
of O
PLMs O
. O

We O
ﬁrst O
give O
an O
overview O
of O
the O
input O
representations O
and O
the O
overall O
architectures O
of O
MPC B-MethodName
- I-MethodName
BERT I-MethodName
. O

When O
constructing O
the O
input O
representations O
, O
in O
order O
to O
consider O
the O
speaker O
information O
of O
each O
utterance O
, O
speaker O
embeddings O
( O
Gu O
et O
al O
. O
, O
2020 O
) O
are O
introduced O
as O
shown O
in O
Figure O
1 O
. O

Considering O
that O
the O
set O
of O
interlocutors O
are O
inconsistent O
in O
different O
conversations O
, O
a O
position O
- O
based O
interlocutor O
embedding O
table O
is O
initialized O
randomly O
at O
ﬁrst O
and O
updated O
during O
pre O
- O
training O
, O
which O
means O
each O
interlocutor O
in O
a O
conversation O
is O
assigned O
with O
an O
embedding O
vector O
according O
to O
the O
order O
it O
appears O
in O
the O
conversation O
. O

Then O
, O
the O
speaker O
embeddings O
for O
each O
utterance O
can O
be O
derived O
bylooking O
up O
this O
embedding O
table O
. O

The O
speaker O
embeddings O
are O
combined O
with O
standard O
token O
, O
position O
and O
segmentation O
embeddings O
and O
are O
then O
encoded O
by O
BERT B-MethodName
. O

The O
output O
embeddings O
of O
BERT B-MethodName
corresponding O
to O
different O
input O
tokens O
are O
utilized O
by O
different O
self O
- O
supervised O
tasks O
for O
further O
calculation O
. O

3.2 O
Tasks O
of O
Interlocutor O
Structure O
Modeling O
The O
ﬁrst O
three O
tasks O
follow O
the O
semantics O
- O
tostructure O
manner O
. O

In O
MPC B-MethodName
- I-MethodName
BERT I-MethodName
, O
each O
interlocutor O
is O
described O
through O
the O
encoded O
representations O
of O
the O
utterances O
it O
says O
. O

Thus O
, O
the O
representations O
of O
utterance O
semantics O
are O
utilized O
to O
construct O
the O
conversation O
structure O
. O

Figure O
1 O
shows O
the O
input O
representations O
and O
the O
model O
architectures O
of O
these O
three O
tasks O
. O

A O
[ O
CLS O
] O
token O
is O
inserted O
at O
the O
start O
of O
each O
utterance O
, O
denoting O
its O
utterancelevel O
representation O
. O

Then O
, O
all O
utterances O
in O
a O
conversation O
are O
concatenated O
and O
a O
[ O
SEP O
] O
token O
is O
inserted O
at O
the O
end O
of O
the O
whole O
sequence O
. O

It O
is O
notable O
that O
these O
three O
tasks O
share O
the O
same O
form O
of O
input O
data O
. O

Thus O
, O
the O
input O
only O
needs O
to O
be O
encoded O
once O
by O
BERT B-MethodName
while O
the O
output O
can O
be O
fed O
into O
three O
tasks O
, O
which O
is O
computation O
- O
efﬁcient O
. O

As O
shown O
in O
Figure O
1 O
, O
a O
task O
- O
dependent O
non O
- O
linear O
transformation O
layer O
is O
placed O
on O
top O
of O
BERT B-MethodName
in O
order O
to O
adapt O
the O
output O
of O
BERT B-MethodName
to O
different O
tasks O
. O

We O
will O
describe O
the O
details O
of O
these O
tasks O
as O
follows O
. O

3.2.1 O
Reply O
- O
to O
Utterance O
Recognition O
To O
enable O
the O
model O
to O
recognize O
the O
addressee O
of O
each O
utterance O
, O
a O
self O
- O
supervised O
task O
named O
replyto O
utterance O
recognition O
( O
RUR B-TaskName
) O
is O
proposed O
to O
learn O
which O
preceding O
utterance O
the O
current O
utterance O
replies O
to O
. O

After O
encoded O
by O
BERT B-MethodName
, O
we O
extract O
the O
contextualized O
representations O
for O
each O
[ O
CLS O
] O
token O
representing O
individual O
utterances O
. O

Next O
, O
a O
non O
- O
linear O
transformation O
followed O
by O
a O
layer O
normalization O
are O
performed O
to O
derive O
the O
utterance O
representations O
for O
this O
speciﬁc O
task O
fuRUR B-TaskName
igN O
i=1 O
, O
where O
uRUR B-TaskName
i2Rdandd= O
768 O
. O

Then O
, O
for O
a O
speciﬁc O
utterance O
U O
i O
, O
its O
matching O
scores O
with O
all O
its O
preceding O
utterances O
are O
calculated O
as O
mij O
= O
softmax O
( O
uRUR B-TaskName
> O
iAruruRUR B-TaskName
j);(1 O
) O
where O
Arur2Rddis O
a O
linear O
transformation O
, O
mij O
denotes O
the O
matching O
degree O
of O
U O
jbeing O
the O
replyto O
utterance O
of O
U O
i O
, O
and O
1j O
< O

i O
. O

We O
construct O
a O
setSby O
sampling O
a O
certain O
number O
of O
utterances3685 O
Ui O
’ O
  O
Ui O
  O
UN O
  O
[ O
SEP O
] O
InputToken O
Embeddings O
Segment O
Embeddings O
Position O
Embeddings O
Speaker O
Embeddings O
... O
...... O
... O
... O
... O
... O
... O
Pre O
- O
trained O
Language O
Model O
( O
BERT B-MethodName
) O
E[CLS O
] O
  O
EU_i O
’ O
  O
E[CLS O
] O
  O
EU_i O
  O
E[CLS O
] O
  O
EU_N O
  O
E[SEP O
] O
Output O
... O
... O

[ O
CLS O
] O
  O

[ O
CLS O
] O
  O

[ O
CLS O
] O
( O
a O
) O
Reply O
-to O

Utterance O
Recognition O
Non O
- O
linear O
Transformation O
+ O
Layer O
Normalization O
ui'RUR B-TaskName
  O
uiRUR B-TaskName
  O
uNRUR B-TaskName
... O
... O

mij O
...... O
... O
......... O

Uj O
’ O
  O
Uj O
... O
  O

[ O
CLS O
] O
  O

[ O
CLS O
] O
... O
... O
... O
... O
... O
... O
... O
E[CLS O
] O
  O
EU_j O
’ O
  O
E[CLS O
] O
  O
EU_j O
... O
... O
uj'RUR B-TaskName
  O
ujRUR B-TaskName
... O

... O
( O
b O
) O
Identical O
Speaker O
Searching O
Non O
- O
linear O
Transformation O
+ O
Layer O
Normalization O
ui'iss O
  O
uiiss O
  O
uNiss O
... O
... O
... O
  O
uj'iss O
  O
ujiss O
... O
... O
( O
c O
) O
Pointer O
Consistency O
Distinction O
Non O
- O
linear O
Transformation O
+ O
Layer O
Normalization O
ui'pcd O
  O
uipcd O
  O
uNpcd O
... O
... O

... O
  O
uj'pcd O
  O
ujpcd O
... O

... O
Pointer O
   O
Pointer O
  O
Similarity O
Classifier O
... O

Figure O
1 O
: O
Input O
representations O
and O
model O
architectures O
of O
the O
three O
self O
- O
supervised O
tasks O
for O
interlocutor O
structure O
modeling O
, O
including O
( O
a O
) O
reply O
- O
to O
utterance O
recognition O
, O
( O
b O
) O
identical O
speaker O
searching O
and O
( O
c O
) O
pointer O
consistency O
distinction O
. O

in O
a O
conversation O
and O
this O
recognition O
operation O
is O
performed O
for O
each O
utterance O
in O
S. O
Meanwhile O
, O
a O
dynamic O
sampling O
strategy O
is O
adopted O
so O
that O
models O
can O
see O
more O
samples O
. O

Finally O
, O
the O
pretraining O
objective O
of O
this O
self O
- O
supervised O
task O
is O
to O
minimize O
the O
cross O
- O
entropy O
loss O
as O
Lrur= X O
i2Si 1X O
j=1yijlog(mij O
) O
; O
( O
2 O
) O
where O
yij= O
1if O

Ujis O
the O
reply O
- O
to O
utterance O
of O
U O
i O
andyij= O
0otherwise O
. O

3.2.2 O
Identical O
Speaker O
Searching O
Having O
knowledge O
of O
who O
is O
the O
speaker O
of O
an O
utterance O
is O
also O
important O
for O
MPC O
. O

The O
task O
ofidentical O
speaker O
searching O
( O
ISS O
) O
is O
designed O
by O
masking O
the O
speaker O
embedding O
of O
a O
speciﬁc O
utterance O
in O
the O
input O
representation O
, O
and O
aims O
to O
predict O
its O
speaker O
given O
the O
conversation O
. O

Since O
the O
set O
of O
interlocutors O
vary O
across O
conversations O
, O
the O
task O
of O
predicting O
the O
speaker O
of O
an O
utterance O
is O
reformulated O
as O
searching O
for O
the O
utterances O
sharing O
the O
identical O
speaker O
. O

First O
, O
for O
a O
speciﬁc O
utterance O
, O
its O
speaker O
embedding O
is O
masked O
with O
a O
special O
[ O
Mask O
] O
interlocutor O
embedding O
to O
avoid O
information O
leakage O
. O

Given O
the O
utterance O
representations O
for O
this O
speciﬁc O
task O
fuiss O
igN O
i=1where O
uiss O
i2Rd O
, O
the O
matching O
scores O
of O
Uiwith O
all O
its O
preceding O
utterances O
are O
calculated O
similarly O
with O
Eq O
. O

( O
1 O
) O
. O

Here O
, O
mijdenotes O
thematching O
degree O
of O
U O
jsharing O
the O
same O
speaker O
with O
U O
i. O

For O
each O
instance O
in O
the O
dynamic O
sampling O
setS O
, O
there O
must O
be O
an O
utterance O
in O
previous O
turns O
sharing O
the O
same O
speaker O
. O

Otherwise O
, O
it O
is O
removed O
out O
of O
the O
set O
. O

Finally O
, O
the O
pre O
- O
training O
objective O
of O
this O
task O
is O
to O
minimize O
the O
cross O
- O
entropy O
loss O
similarly O
with O
Eq O
. O

( O
2 O
) O
. O

Here O
, O
yij= O
1if O
Ujshares O
the O
same O
speaker O
with O
U O
iandyij= O
0otherwise O
. O

3.2.3 O
Pointer O
Consistency O
Distinction O
We O
design O
a O
task O
named O
pointer O
consistency O
distinction O
( O
PCD O
) O
to O
jointly O
model O
speakers O
and O
addressees O
in O
MPC O
. O

In O
this O
task O
, O
a O
pair O
of O
utterances O
representing O
the O
“ O
reply O
- O
to O
” O
relationship O
is O
deﬁned O
as O
a O
speaker O
- O
to O
- O
addressee O
pointer O
. O

Here O
, O
we O
assume O
that O
the O
representations O
of O
two O
pointers O
directing O
from O
the O
same O
speaker O
to O
the O
same O
addressee O
should O
be O
consistent O
. O

As O
illustrated O
in O
Figure O
2 O
( O
a O
) O
, O
speaker O
S O
mspeaks O
U O
iand O
U O
jwhich O
reply O
to O
U O

i0and O

U O
j0from O
speaker O
S O
nrespectively O
. O

Thus O
, O
the O
utterance O
tuples O
( O
U O
i O
, O
Ui0 O
) O
and O
( O
U O
j O
, O
Uj0 O
) O
both O
represent O
the O
pointer O
of O
S O
m O
- O
to O
- O
S O
nand O
their O
pointer O
representations O
should O
be O
consistent O
.. O

Given O
the O
utterance O
representations O
for O
this O
speciﬁc O
taskfupcd O
igN O
i=1where O
upcd O
i2Rd O
, O
we O
ﬁrst O
capture O
the O
pointer O
information O
contained O
in O
each O
utterance O
tuple O
. O

The O
element O
- O
wise O
difference O
and O
multiplication O
between O
an O
utterance O
tuple O
( O
U O
i O
, O
Ui0 O
) O
are O
computed O
and O
are O
concatenated O
as O
pii0= O

[ O
upcd O
i upcd O
i0;upcd O
i O
 O
upcd O
i0 O
] O
; O
( O
3)3686 O
Ui O
   O
Ui O
  O
... O

   O

Uj O
   O
Uj O
Sn O
Sm O
... O
... O
: O
Speaker O
: O
Utterance O
: O
Utterance O
-to O
- O
utterance O
: O
Speaker O
-to O
- O
utterance O
( O
a O
) O
Pointer O
consistency O
distinction O
U1 O
  O
U2 O
  O
U3 O
  O
U5 O
  O
U8 O
U4 O
  O
U6 O
U7 O
U9(b O
) O

Shared O
node O
detection O
Figure O
2 O
: O
Illustrations O
of O
the O
self O
- O
supervised O
tasks O
of O
( O
a O
) O
pointer O
consistency O
distinction O
and O
( O
b O
) O
shared O
node O
detection O
. O

Rectangles O
denote O
utterances O
, O
circles O
denote O
interlocutors O
, O
a O
solid O
line O
denotes O
an O
utterance O
replying O
to O
an O
utterance O
, O
and O
a O
dashed O
line O
denotes O
an O
utterance O
from O
an O
interlocutor O
. O

where O
pii02R2d O
. O

Then O
, O
we O
compress O
pii0and O
obtain O
the O
pointer O
representation O
pii0as O
pii0 O
= O
ReLU O
( O
pii0Wpcd+bpcd O
) O
; O
( O
4 O
) O
where O
Wpcd2R2ddandbpcd2Rdare O
parameters O
. O

Identically O
, O
a O
consistent O
pointer O
representations O
pjj0and O
an O
inconsistent O
one O
pkk0sampled O
from O
this O
conversation O
are O
obtained O
. O

The O
similarities O
between O
every O
two O
pointers O
are O
calculated O
as O
mij O
= O
sigmoid O
( O
p O
> O
ii0Apcdpjj0 O
) O
; O
( O
5 O
) O
where O
mijdenotes O
the O
matching O
degree O
of O
pointer O
pii0being O
consistent O
with O
pointer O
pjj0.mikcan O
be O
derived O
accordingly O
. O

Finally O
, O
the O
pre O
- O
training O
objective O
of O
this O
task O
is O
to O
minimize O
the O
hinge O
loss O
which O
enforces O
mijto O
be O
larger O
than O
mikby O
at O
least O
a O
margin O
as O
Lpcd O
= O
maxf0; mij+mikg O
: O
( O
6 O
) O
3.3 O
Tasks O
of O
Utterance O
Semantics O
Modeling O
Intuitively O
, O
the O
conversation O
structure O
might O
inﬂuence O
the O
information O
ﬂow O
, O
so O
that O
it O
can O
be O
used O
to O
strengthen O
the O
representations O
of O
utterance O
semantics O
. O

Thus O
, O
two O
self O
- O
supervised O
tasks O
following O
the O
structure O
- O
to O
- O
semantics O
manner O
are O
designed O
. O

3.3.1 O
Masked O
Shared O
Utterance O
Restoration O
There O
are O
usually O
several O
utterances O
replying O
- O
to O
a O
shared O
utterance O
in O
MPC O
. O

Intuitively O
, O
a O
shared O
utterance O
is O
semantically O
relevant O
to O
more O
utterances O
in O
the O
context O
than O
non O
- O
shared O
ones O
. O

Based O
on O
this O
characteristic O
, O
we O
design O
a O
task O
named O
masked O
shared O
utterance O
restoration O
( O
MSUR O
) O
. O

We O
ﬁrst O
randomly O
sample O
an O
utterance O
from O
all O
shared O
utterances O
in O
a O
conversation O
and O
all O
tokens O
in O
this O
sampled O
utterance O
are O
masked O
with O
a O
[ O
MASK]token O
. O

Then O
the O
model O
is O
enforced O
to O
restore O
the O
masked O
utterance O
given O
the O
rest O
conversation O
. O

Formally O
, O
assuming O
U O
ias O
the O
masked O
shared O
utterance O
and O
lias O
the O
number O
of O
tokens O
in O
U O
i. O
Given O
the O
token O
representations O
for O
this O
task O
fumsur O
i;tgli O
t=1 O
where O
umsur O
i;t2Rd O
, O
the O
probability O
distribution O
of O
each O
masked O
token O
can O
be O
calculated O
as O
pui;t O
= O
softmax O
( O
umsur O
i;tWmsur O
+ O
bmsur);(7 O
) O
where O
Wmsur2RdVis O
the O
token O
embedding O
table O
, O
Vdenotes O
the O
vocabulary O
size O
, O
and O
bmsur2 O
RVis O
a O
bias O
vector O
. O

Finally O
, O
the O
pre O
- O
training O
objective O
of O
this O
self O
- O
supervised O
task O
is O
to O
minimize O
the O
negative O
log O
- O
likelihood O
loss O
as O
Lmsur O
= O
 1 O

liliX O
t=1log O
p O
ui;t O
; O
( O
8) O
where O
pui;tis O
the O
element O
in O
pui;tcorresponding O
to O
the O
original O
token O
. O

3.3.2 O
Shared O
Node O
Detection O
A O
full O
MPC O
instance O
can O
be O
divided O
into O
several O
sub O
- O
conversations O
and O
we O
assume O
that O
the O
representations O
of O
sub O
- O
conversations O
under O
the O
same O
parent O
node O
tend O
to O
be O
similar O
. O

As O
illustrated O
in O
Figure O
2 O
( O
b O
) O
, O
two O
sub O
- O
conversations O
fU3 O
, O
U5 O
, O
U7 O
, O
U8gandfU4 O
, O
U6 O
, O
U9gshare O
the O
same O
parent O
node O
U2 O
. O

Thus O
, O
they O
should O
be O
semantically O
relevant O
. O

Under O
this O
assumption O
, O
we O
design O
a O
self O
- O
supervised O
task O
named O
shared O
node O
detection O
( O
SND O
) O
, O
which O
utilizes O
the O
conversation O
structure O
to O
strengthen O
the O
capability O
of O
models O
on O
measuring O
the O
semantic O
relevance O
of O
two O
sub O
- O
conversations O
. O

We O
ﬁrst O
construct O
the O
pre O
- O
training O
samples O
for O
this O
task O
. O

Empirically O
, O
only O
the O
sub O
- O
conversations O
under O
the O
top O
shared O
node O
in O
a O
conversation O
are O
collected O
in O
order O
to O
ﬁlter O
out O
the O
sub O
- O
conversations O
with O
few O
utterances O
. O

Given O
a O
full O
MPC O
, O
the O
two O
sub O
- O
conversations O
with O
the O
most O
utterances O
form O
a O
positive O
pair O
. O

For O
each O
positive O
pair O
, O
we O
replace O
one O
of O
its O
elements O
with O
another O
sub O
- O
conversation O
randomly O
sampled O
from O
the O
training O
corpus O
to O
form O
a O
negative O
pair O
. O

Formally O
, O
given O
two O
sub O
- O
conversations O
ciand O
cj O
, O
utterances O
in O
each O
sub O
- O
conversation O
are O
ﬁrst O
concatenated O
respectively O
to O
form O
two O
segments O
. O

Then O
, O
the O
two O
segments O
are O
concatenated O
with O
a O
[ O
SEP O
] O
token O
and O
a O
[ O
CLS O
] O
token O
is O
inserted O
at O
the O
beginning O
of O
the O
whole O
sequence O
. O

This O
sequence O
are O
encoded O
by O
BERT B-MethodName
to O
derive O
the O
contextualized3687representation O
for O
the O
[ O
CLS O
] O
token O
. O

A O
non O
- O
linear O
transformation O
with O
sigmoid O
activation O
is O
further O
applied O
to O
this O
representation O
for O
calculating O
the O
matching O
score O
mij O
, O
i.e. O
, O
the O
probability O
of O
ciand O
cjsharing O
the O
same O
parent O
node O
. O

Finally O
, O
the O
pretraining O
objective O
of O
this O
task O
is O
to O
minimize O
the O
cross O
- O
entropy O
loss O
as O
Lsnd= [yijlog(mij O
) O
+ O
( O
1 yij)log(1 mij O
) O
] O
; O
( O
9 O
) O
where O
yij= O
1 O
ifciandcjshare O
the O
same O
parent O
node O
and O
yij= O
0otherwise O
. O

3.4 O
Multi O
- O
task O
Learning O
In O
addition O
, O
we O
also O
adopt O
the O
tasks O
of O
masked O
language O
model O
( O
MLM O
) O
and O
next O
sentence O
prediction O
( O
NSP O
) O
in O
original O
BERT B-MethodName
pre O
- O
training O
( O
Devlin O
et O
al O
. O
, O
2019 O
) O
, O
which O
have O
been O
proven O
effective O
for O
incorporating O
domain O
knowledge O
( O
Gu O
et O
al O
. O
, O
2020 O
; O
Gururangan O
et O
al O
. O
, O
2020 O
) O
. O

Finally O
, O
MPCBERT B-MethodName
is O
trained O
by O
performing O
multi O
- O
task O
learning O
that O
minimizes O
the O
sum O
of O
all O
loss O
functions O
as O
L O
= O
Lrur+Liss+Lpcd+Lmsur O
+ O
Lsnd+Lmlm+Lnsp:(10 O
) O
4 O
Downstream O
Tasks O
4.1 O
Addressee B-TaskName
Recognition I-TaskName
Given O
a O
multi O
- O
party O
conversation O
where O
part O
of O
the O
addressees O
are O
unknown O
, O
Ouchi O
and O
Tsuboi O
( O
2016 O
) O
and O
Zhang O
et O
al O
. O

( O
2018a O
) O
recognized O
an O
addressee O
of O
the O
last O
utterance O
. O

Le O
et O
al O
. O

( O
2019 O
) O
recognized O
addressees O
of O
all O
utterances O
in O
a O
conversation O
. O

In O
this O
paper O
, O
we O
follow O
the O
more O
challenging O
setting O
in O
Le O
et O
al O
. O

( O
2019 O
) O
. O

Formally O
, O
models O
are O
asked O
to O
predict O
f^angN O
n=1 O
givenf(sn O
; O
un O
; O
an)gN O
n=1nfangN O
n=1 O
, O
where O
^anis O
selected O
from O
the O
interlocutor O
set O
in O
this O
conversation O
andndenotes O
exclusion O
. O

When O
applying O
MPC B-MethodName
- I-MethodName
BERT I-MethodName
, O
this O
task O
is O
reformulated O
as O
ﬁnding O
a O
preceding O
utterance O
from O
the O
same O
addressee O
. O

Its O
RUR B-TaskName
matching O
scores O
with O
all O
preceding O
utterances O
are O
calculated O
following O
Eq O
. O

( O
1 O
) O
. O

Then O
, O
the O
utterance O
with O
the O
highest O
score O
is O
selected O
and O
the O
speaker O
of O
the O
selected O
utterance O
is O
considered O
as O
the O
recognized O
addressee O
. O

Finally O
, O
the O
ﬁne O
- O
tuning O
objective O
of O
this O
task O
is O
to O
minimize O
the O
crossentropy O
loss O
as O
Lar= NX O
i=2i 1X O
j=1yijlog(mij O
) O
; O
( O
11)where O
mijis O
deﬁned O
in O
Eq O
. O

( O
1 O
) O
, O
yij= O
1 O
if O
the O
speaker O
of O
U O
jis O
the O
addressee O
of O
U O
iandyij= O
0 O
otherwise O
. O

4.2 O
Speaker B-TaskName
Identiﬁcation I-TaskName
This O
task O
aims O
to O
identify O
the O
speaker O
of O
the O
last O
utterance O
in O
a O
conversation O
. O

Formally O
, O
models O
are O
asked O
to O
predict O
^sNgivenf(sn O
; O
un O
; O
an)gN O
n=1nsN O
, O
where O
^sNis O
selected O
from O
the O
interlocutor O
set O
in O
this O
conversation O
. O

When O
applying O
MPC B-MethodName
- I-MethodName
BERT I-MethodName
, O
this O
task O
is O
reformulated O
as O
identifying O
the O
utterances O
sharing O
the O
same O
speaker O
. O

For O
the O
last O
utterance O
UN O
, O
its O
speaker O
embedding O
is O
masked O
and O
its O
ISS O
matching O
scores O
mNjwith O
all O
preceding O
utterances O
are O
calculated O
following O
Section O
3.2.2 O
. O

The O
ﬁnetuning O
objective O
of O
this O
task O
is O
to O
minimize O
the O
cross O
- O
entropy O
loss O
as O
Lsi= N 1X O
j=1yNjlog(mNj O
) O
; O
( O
12 O
) O
where O
yNj= O
1if O
Ujshares O
the O
same O
speaker O
with O
UNandyNj= O
0otherwise O
. O

4.3 O
Response B-TaskName
Selection I-TaskName
This O
task O
asks O
models O
to O
select O
^uNfrom O
a O
set O
of O
response O
candidates O
given O
the O
conversation O
context O
f(sn O
; O
un O
; O
an)gN O
n=1nuN. O

The O
key O
is O
to O
measure O
the O
similarity O
between O
two O
segments O
of O
context O
and O
response O
. O

We O
concatenate O
each O
response O
candidate O
with O
the O
context O
and O
extract O
the O
contextualized O
representation O
e[CLS O
] O
for O
the O
ﬁrst O
[ O
CLS O
] O
token O
using O
MPC B-MethodName
- I-MethodName
BERT I-MethodName
. O

Then O
, O
e[CLS O
] O
is O
fed O
into O
a O
nonlinear O
transformation O
with O
sigmoid O
activation O
to O
obtain O
the O
matching O
score O
between O
the O
context O
and O
the O
response O
. O

Finally O
, O
the O
ﬁne O
- O
tuning O
objective O
of O
this O
task O
is O
to O
minimize O
the O
cross O
- O
entropy O
loss O
according O
to O
the O
true O
/ O
false O
labels O
of O
responses O
in O
the O
training O
set O
as O
Lrs= [ylog(mcr)+(1 y)log(1 mcr)];(13 O
) O
where O
y= O
1if O
the O
response O
ris O
a O
proper O
one O
for O
the O
context O
c O
; O
otherwise O
y= O
0 O
. O
5 O
Experiments O
5.1 O
Datasets O
We O
evaluated O
our O
proposed O
methods O
on O
two O
Ubuntu B-DatasetName
IRC I-DatasetName
benchmarks O
. O

One O
was O
released O
by O
Hu O
et O
al O
. O
( O
2019 O
) O
, O
in O
which O
both O
speaker O
and O
addressee O
labels O
was O
provided O
for O
each O
utterance O
. O

The O
other O
benchmark O
was O
released O
by O
Ouchi O
and O
Tsuboi3688Datasets O
Train O
Valid O
Test O
Hu O
et O
al O
. O

( O
2019 O
) O
311,725 O
5,000 O
5,000 O
Ouchi O
and O
Tsuboi O
( O
2016)Len-5 O
461,120 O
28,570 O
32,668 O
Len-10 O
495,226 O
30,974 O
35,638 O
Len-15 O
489,812 O
30,815 O
35,385 O
Table O
2 O
: O
Statistics O
of O
the O
two O
benchmarks O
evaluated O
in O
this O
paper O
. O
( O
2016 O
) O
. O

Here O
, O
we O
adopted O
the O
version O
shared O
in O
Le O
et O
al O
. O

( O
2019 O
) O
for O
fair O
comparison O
. O

The O
conversation O
sessions O
were O
separated O
into O
three O
categories O
according O
to O
the O
session O
length O
( O
Len5 O
, O
Len-10 O
and O
Len-15 O
) O
following O
the O
splitting O
strategy O
of O
previous O
studies O
( O
Ouchi O
and O
Tsuboi O
, O
2016 O
; O
Zhang O
et O
al O
. O
, O
2018a O
; O
Le O
et O
al O
. O
, O
2019 O
) O
. O

Table O
2 O
presents O
the O
statistics O
of O
the O
two O
benchmarks O
evaluated O
in O
our O
experiments O
. O

5.2 O
Baseline O
Models O
Non O
- O
pre O
- O
training O
- O
based O
models O
Ouchi O
and O
Tsuboi O
( O
2016 O
) O
proposed O
a O
dynamic O
model O
DRNN B-MethodName
which O
updated O
speaker O
embeddings O
with O
the O
conversation O
ﬂow O
. O

Zhang O

et O
al O
. O

( O
2018a O
) O
improved O
DRNN B-MethodName
to O
SI O
- O
RNN B-MethodName
which O
updated O
speaker O
embeddings O
role O
- O
sensitively O
. O

Le O
et O

al O
. O
( O
2019 O
) O
proposed O
W2W B-MethodName
which O
jointly O
modeled O
interlocutors O
and O
utterances O
in O
a O
uniform O
framework O
, O
and O
predicted O
all O
addressees O
. O

Pre O
- O
training O
- O
based O
models O
BERT B-MethodName
( O
Devlin O
et O
al O
. O
, O
2019 O
) O
was O
pre O

-trained O
to O
learn O
general O
language O
representations O
with O
MLM O
and O
NSP O
tasks O
. O

SABERT B-MethodName
( O
Gu O
et O
al O
. O
, O
2020 O
) O
added O
speaker O
embeddings O
and O
further O
pre O
- O
trained O
BERT B-MethodName
on O
a O
domain O
- O
speciﬁc O
corpus O
to O
incorporate O
domain O
knowledge O
. O

We O
re O
- O
implemented O
SA B-MethodName
- I-MethodName
BERT I-MethodName
with O
the O
pre O
- O
training O
corpus O
used O
in O
this O
paper O
to O
ensure O
fair O
comparison O
. O

5.3 O
Implementation O
Details O
The O
version O
of O
BERT B-MethodName
- I-MethodName
base I-MethodName
- I-MethodName
uncased I-MethodName
was O
adopted O
for O
all O
our O
experiments O
. O

For O
pre O
- O
training O
, O
GELU O
( O
Hendrycks O
and O
Gimpel O
, O
2016 O
) O
was O
employed O
as O
the O
activation O
for O
all O
non O
- O
linear O
transformations O
. O

The O
Adam B-HyperparameterValue
method O
( O
Kingma O
and O
Ba O
, O
2015 O
) O
was O
employed O
for O
optimization O
. O

The O
learning B-MetricName
rate I-MetricName
was O
initialized O
as O
0.00005 B-HyperparameterValue
and O
the O
warmup B-MetricName
proportion I-MetricName
was O
set O
to O
0.1 B-HyperparameterValue
. O

We O
pre O
- O
trained O
BERT B-MethodName
for O
10 B-HyperparameterValue
epochs B-HyperparameterName
. O

The O
training O
set O
of O
the O
dateset O
used O
in O
Hu O
et O
al O
. O

( O
2019 O
) O
was O
employed O
for O
pre O
- O
training O
. O

The O
maximum B-HyperparameterName
utterance I-HyperparameterName
number I-HyperparameterName
was O
set O
to O
7 B-HyperparameterValue
. O

The O
maximum B-HyperparameterName
sequence I-HyperparameterName
length I-HyperparameterName
was O
set O
to O
230 B-HyperparameterValue
. O

The O
maximum B-HyperparameterName
sampling I-HyperparameterName
numbers I-HyperparameterName
for O
each O
examplewere O
set O
to O
4 B-HyperparameterValue
for O
RUR B-TaskName
, O
2 B-HyperparameterValue
for O
ISS O
and O
2 B-HyperparameterValue
for O
PCD O
. O
in O
Eq O
. O

( O
6 O
) O
was O
set O
to O
0.4 B-HyperparameterValue
, O
achieving O
the O
best O
performance O
out O
of O
f0.2 B-MetricValue
, O
0.4 B-MetricValue
, O
0.6 B-MetricValue
, O
0.8gon B-MetricValue
the O
validation O
set O
. O

The O
pre O
- O
training O
was O
performed O
using O
a O
GeForce O
RTX O
2080 O

Ti O
GPU O
and O
the O
batch B-HyperparameterName
size I-HyperparameterName
was O
set O
to O
4 B-HyperparameterValue
. O

For O
ﬁne O
- O
tuning O
, O
some O
conﬁgurations O
were O
different O
according O
to O
the O
characteristics O
of O
these O
datasets O
. O

For O
Hu O
et O
al O
. O

( O
2019 O
) O
, O
the O
maximum B-HyperparameterName
utterance I-HyperparameterName
number I-HyperparameterName
was O
set O
to O
7 B-HyperparameterValue
and O
the O
maximum B-HyperparameterName
sequence I-HyperparameterName
length I-HyperparameterName
was O
set O
to O
230 B-HyperparameterValue
. O

For O
the O
three O
experimental O
settings O
in O
Ouchi O
and O
Tsuboi O
( O
2016 O
) O
, O
the O
maximum B-HyperparameterName
utterance I-HyperparameterName
numbers I-HyperparameterName
were O
set O
to O
5 B-HyperparameterValue
, O
10 B-HyperparameterValue
and O
15 B-HyperparameterValue
, O
and O
the O
maximum B-HyperparameterName
sequence I-HyperparameterName
lengths I-HyperparameterName
were O
set O
to O
120 B-HyperparameterValue
, O
220 B-HyperparameterValue
and O
320 B-HyperparameterValue
. O

All O
parameters O
in O
PLMs O
were O
updated O
. O

The O
learning B-HyperparameterName
rate I-HyperparameterName
was O
initialized O
as O
0.00002 B-HyperparameterValue
and O
the O
warmup B-HyperparameterName
proportion I-HyperparameterName
was O
set O
to O
0.1 B-HyperparameterValue
. O

For O
Hu O
et O
al O
. O

( O
2019 O
) O
, O
the O
ﬁne O
- O
tuning O
process O
was O
performed O
for O
10 B-HyperparameterValue
epochs B-HyperparameterName
for O
addressee B-TaskName
recognition I-TaskName
, O
10 B-HyperparameterValue
epochs B-HyperparameterName
for O
speaker B-TaskName
identiﬁcation I-TaskName
, O
and O
5 B-HyperparameterValue
epochs B-HyperparameterName
for O
response B-TaskName
selection I-TaskName
. O

For O
Ouchi O
and O
Tsuboi O
( O
2016 O
) O
, O
the O
ﬁne O
- O
tuning O
epochs B-HyperparameterName
were O
set O
to O
5 B-HyperparameterValue
, O
5 B-HyperparameterValue
and O
3 B-HyperparameterValue
respectively O
. O

The O
ﬁne O
- O
tuning O
was O
also O
performed O
using O
a O
GeForce O
RTX O
2080 O

Ti O
GPU O
. O

The O
batch B-HyperparameterName
sizes I-HyperparameterName
were O
set O
to O
16 B-HyperparameterValue
for O
Hu O
et O
al O
. O

( O
2019 O
) O
, O
and O
40 B-HyperparameterValue
, O
20 B-HyperparameterValue
, O
and O
12 B-HyperparameterValue
for O
the O
three O
experimental O
settings O
in O
Ouchi O
and O
Tsuboi O
( O
2016 O
) O
respectively O
. O

The O
validation O
set O
was O
used O
to O
select O
the O
best O
model O
for O
testing O
. O

All O
codes O
were O
implemented O
in O
the O
TensorFlow O
framework O
( O
Abadi O
et O
al O
. O
, O
2016 O
) O
and O
are O
published O
to O
help O
replicate O
our O
results.1 O
5.4 O
Metrics O
and O
Results O
Addressee B-TaskName
recognition I-TaskName
We O
followed O
the O
metrics O
of O
previous O
work O
( O
Le O
et O
al O
. O
, O
2019 O
) O
by O
employing O
precision@1 B-MetricName
( O
P@1 B-MetricName
) O
to O
evaluate O
each O
utterance O
with O
ground O
truth O
. O

Also O
, O
a O
session O
is O
marked O
as O
positive O
if O
the O
addressees O
of O
all O
its O
utterances O
are O
correctly O
recognized O
, O
which O
is O
calculated O
as O
accuracy B-MetricName
( O
Acc B-MetricName
. O
) O
. O

Table O
3 O
presents O
the O
results O
of O
addressee B-TaskName
recognition I-TaskName
. O

It O
shows O
that O
MPC B-MethodName
- I-MethodName
BERT I-MethodName
outperforms O
the O
best O
performing O
model O
, O
i.e. O
, O
SA B-MethodName
- I-MethodName
BERT I-MethodName
, O
by O
margins O
of O
3.51 B-MetricValue
% I-MetricValue
, O
2.86 B-MetricValue
% I-MetricValue
, O
3.28 B-MetricValue
% I-MetricValue
and O
5.36 B-MetricValue
% I-MetricValue
on O
these O
test O
sets O
respectively O
in O
terms O
of O
Acc B-MetricName
. O
, O
verifying O
the O
effectiveness O
of O
the O
proposed O
ﬁve O
selfsupervised O
tasks O
as O
a O
whole O
. O

To O
further O
illustrate O
the O
effectiveness O
of O
each O
task O
, O
ablation O
tests O
were O
performed O
as O
shown O
in O
the O
last O
ﬁve O
rows O
of O
Table O
3 O
. O

We O
can O
observe O
that O
all O
self O
- O
supervised O
tasks O
are O
useful O
as O
removing O
any O
of O
them O
causes O
performance O
1https://github.com/JasonForJoy/MPC-BERT3689Hu O
et O
al O
. O

( O
2019 O
) O
Ouchi O
and O
Tsuboi O
( O
2016 O
) O

Len-5 O
Len-10 O
Len-15 O
P@1 O
Acc O
. O
P@1 O

Acc O
. O
P@1 O

Acc O
. O
P@1 O

Acc O
. O

Preceding O
( O
Le O
et O
al O
. O
, O
2019 O
) O
- O
- O
63.50 O
40.46 O
56.84 O
21.06 O
54.97 O
13.08 O
Subsequent O
( O
Le O
et O
al O
. O
, O
2019 O
) O
- O
- O
61.03 O
40.25 O
54.57 O
20.26 O
53.07 O
12.79 O
DRNN O
( O
Ouchi O
and O
Tsuboi O
, O
2016 O
) O
- O
- O
72.75 O
58.18 O
65.58 O
34.47 O
62.60 O
22.58 O
SIRNN O
( O
Zhang O
et O
al O
. O
, O
2018a O
) O
- O
- O
75.98 O
62.06 O
70.88 O
40.66 O
68.13 O
28.05 O
W2W O

( O

Le O
et O
al O
. O
, O
2019 O
) O
- O
- O
77.55 O
63.81 O
73.52 O
44.14 O
73.42 O
34.23 O
BERT B-MethodName
( O
Devlin O
et O
al O
. O
, O
2019 O
) O
96.16 O
83.50 O
85.95 O
75.99 O
83.41 O
58.22 O
81.09 O
44.94 O
SA O
- O
BERT B-MethodName
( O
Gu O
et O
al O
. O
, O
2020 O
) O
97.12 O
88.91 O
86.81 O
77.45 O
84.46 O
60.30 O
82.84 O
47.23 O
MPC O
- O
BERT B-MethodName
98.31 O
92.42 O
88.73 O
80.31 O
86.23 O
63.58 O
85.55 O
52.59 O
MPC O
- O
BERT B-MethodName
w/o O
. O

RUR B-TaskName
97.75 O
89.98 O
87.51 O
78.42 O
85.63 O
62.26 O
84.78 O
50.83 O
MPC O
- O
BERT B-MethodName
w/o O
. O

ISS O
98.20 O
91.96 O
88.67 O
80.25 O
86.14 O
63.40 O
85.02 O
51.12 O
MPC O
- O
BERT B-MethodName
w/o O
. O

PCD O
98.20 O
91.90 O
88.51 O
80.06 O
85.92 O
62.84 O
85.21 O
51.17 O
MPC O
- O
BERT B-MethodName
w/o O
. O

MSUR O
98.08 O
91.32 O
88.70 O
80.26 O
86.21 O
63.46 O
85.28 O
51.23 O
MPC O
- O
BERT B-MethodName
w/o O
. O

SND O
98.25 O
92.18 O
88.68 O
80.25 O
86.14 O
63.41 O
85.29 O
51.39 O
Table O
3 O
: O
Evaluation O
results O
of O
addressee O
recognition O
on O
the O
test O
sets O
. O

Results O
except O
ours O
are O
cited O
from O
Le O
et O
al O
. O
( O
2019 O
) O
. O

Numbers O
in O
bold O
denote O
that O
the O
improvement O
over O
the O
best O
performing O
baseline O
is O
statistically O
signiﬁcant O
( O
t O
- O
test O
with O
p O
- O
value O
< O
0.05 O
) O
. O

Hu O
et O

al O
. O

( O
2019 O
) O
Ouchi O
and O
Tsuboi O
( O
2016 O
) O

Len-5 O
Len-10 O
Len-15 O
BERT B-MethodName

( O
Devlin O
et O
al O
. O
, O
2019 O
) O
71.81 O
62.24 O
53.17 O
51.58 O
SA O
- O
BERT B-MethodName
( O
Gu O
et O
al O
. O
, O
2020 O
) O
75.88 O
64.96 O
57.62 O
54.28 O
MPC O
- O
BERT B-MethodName
83.54 O
67.56 O
61.00 O
58.52 O
MPC O
- O
BERT B-MethodName
w/o O
. O

RUR B-TaskName
82.48 O
66.88 O
60.12 O
57.33 O
MPC O
- O
BERT B-MethodName
w/o O
. O

ISS O
77.95 O
66.77 O
60.03 O
56.73 O
MPC O
- O
BERT B-MethodName
w/o O
. O

PCD O
83.39 O
67.12 O
60.62 O
58.00 O
MPC O
- O
BERT B-MethodName
w/o O
. O

MSUR O
83.51 O
67.21 O
60.76 O
58.03 O
MPC O
- O
BERT B-MethodName
w/o O
. O

SND O
83.47 O
67.04 O
60.44 O
58.12 O
Table O
4 O
: O
Evaluation O
results O
of O
speaker O
identiﬁcation O
on O
the O
test O
sets O
in O
terms O
of O
P@1 B-MetricName
. O

Numbers O
in O
bold O
denote O
that O
the O
improvement O
over O
the O
best O
performing O
baseline O
is O
statistically O
signiﬁcant O
( O
t O
- O
test O
with O
p O
- O
value O
< O
0.05 O
) O
. O
drop O
. O

Among O
the O
ﬁve O
tasks O
, O
RUR B-TaskName
plays O
the O
most O
important O
role O
, O
and O
the O
tasks O
focusing O
on O
modeling O
interlocutor O
structure O
contribute O
more O
than O
those O
for O
utterance O
semantics O
. O

Speaker B-TaskName
identiﬁcation I-TaskName
Similarly O
, O
P@1 B-MetricName
was O
employed O
as O
the O
evaluation O
metric O
of O
speaker B-TaskName
identiﬁcation I-TaskName
for O
the O
last O
utterance O
of O
a O
conversation O
and O
the O
results O
are O
shown O
in O
Table O
4 O
. O

It O
shows O
that O
MPC B-MethodName
- I-MethodName
BERT I-MethodName
outperforms O
SA B-MethodName
- I-MethodName
BERT I-MethodName
by O
margins O
of O
7.66 B-MetricValue
% I-MetricValue
, O
2.60 B-MetricValue
% I-MetricValue
, O
3.38 B-MetricValue
% I-MetricValue
and O
4.24 B-MetricValue
% I-MetricValue
respectively O
in O
terms O
of O
P@1 B-MetricName
. O

Besides O
, O
from O
the O
ablation O
results O
we O
ﬁnd O
that O
all O
tasks O
are O
useful O
for O
improving O
the O
performance O
of O
speaker B-TaskName
identiﬁcation I-TaskName
and O
ISS O
and O
RUR B-TaskName
contribute O
the O
most O
. O

In O
particular O
, O
removing O
PCD O
, O
MSUR O
and O
SND O
only O
leads O
to O
slight O
performance O
drop O
. O

The O
reason O
might O
bethat O
the O
information O
conveyed O
by O
these O
tasks O
is O
redundant O
. O

Response B-TaskName
selection I-TaskName
The O
R B-MetricName
n@kmetrics I-MetricName
adopted O
by O
previous O
studies O
( O
Ouchi O
and O
Tsuboi O
, O
2016 O
; O
Zhang O
et O
al O
. O
, O
2018a O
) O
were O
used O
here O
. O

Each O
model O
was O
tasked O
with O
selecting O
kbest O
- O
matched O
responses O
fromnavailable O
candidates O
, O
and O
we O
calculated O
the O
recall O
as O
R B-MetricName
n@k I-MetricName
. O

Two O
settings O
were O
followed O
in O
which O
kwas O
set O
to O
1 B-MetricValue
and O
nwas O
set O
to O
2 B-MetricValue
or O
10 B-MetricValue
. O

Table O
5 O
presents O
the O
results O
of O
response B-TaskName
selection I-TaskName
. O

It O
shows O
that O
MPC B-MethodName
- I-MethodName
BERT I-MethodName
outperforms O
SABERT B-MethodName
by O
margins O
of O
3.82 B-MetricValue
% I-MetricValue
, O
2.71 B-MetricValue
% I-MetricValue
, O
2.55 B-MetricValue
% I-MetricValue
and O
3.22 B-MetricValue
% I-MetricValue
respectively O
in O
terms O
of O
R B-MetricName
10@1 I-MetricName
. O

Ablation O
tests O
show O
that O
SND B-TaskName
is O
the O
most O
useful O
task O
for O
response B-TaskName
selection I-TaskName
and O
the O
two O
tasks O
focusing O
on O
the O
utterance O
semantics O
contribute O
more O
than O
those3690Hu O
et O
al O
. O

( O
2019 O
) O
Ouchi O
and O
Tsuboi O
( O
2016 O
) O

Len-5 O
Len-10 O
Len-15 O
R2@1 O
R10@1 O
R2@1 O

R10@1 O

R2@1 O

R10@1 O

R2@1 O

R10@1 O
DRNN O
( O
Ouchi O
and O
Tsuboi O
, O
2016 O
) O
- O
- O
76.07 O
33.62 O
78.16 O
36.14 O
78.64 O
36.93 O
SIRNN O
( O
Zhang O
et O
al O
. O
, O
2018a O
) O
- O
- O
78.14 O
36.45 O
80.34 O
39.20 O
80.91 O
40.83 O
BERT B-MethodName
( O
Devlin O
et O

al O
. O
, O
2019 O
) O
92.48 O
73.42 O
85.52 O
53.95 O
86.93 O
57.41 O
87.19 O
58.92 O
SA O
- O
BERT B-MethodName
( O
Gu O
et O
al O
. O
, O
2020 O
) O
92.98 O
75.16 O
86.53 O
55.24 O
87.98 O
59.27 O
88.34 O
60.42 O
MPC O
- O
BERT B-MethodName
94.90 O
78.98 O
87.63 O
57.95 O
89.14 O
61.82 O
89.70 O
63.64 O
MPC O
- O
BERT B-MethodName
w/o O
. O

RUR B-TaskName
94.48 O
78.16 O
87.20 O
57.56 O
88.96 O
61.47 O
89.07 O
63.24 O
MPC O
- O
BERT B-MethodName
w/o O
. O

ISS O
94.58 O
78.82 O
87.54 O
57.77 O
88.98 O
61.76 O
89.58 O
63.51 O
MPC O
- O
BERT B-MethodName
w/o O
. O

PCD O
94.66 O
78.70 O
87.50 O
57.51 O
88.75 O
61.62 O
89.45 O
63.46 O
MPC O
- O
BERT B-MethodName
w/o O
. O

MSUR O
94.36 O
78.22 O
87.11 O
57.58 O
88.59 O
61.05 O
89.25 O
63.20 O
MPC O
- O
BERT B-MethodName
w/o O
. O

SND O
93.92 O
76.96 O
87.30 O
57.54 O
88.77 O
61.54 O
89.27 O
63.34 O
Table O
5 O
: O
Evaluation O
results O
of O
response O
selection O
on O
the O
test O
sets O
. O

Results O
except O
ours O
are O
cited O
from O
Ouchi O
and O
Tsuboi O
( O
2016 O
) O
and O
Zhang O
et O
al O
. O
( O
2018a O
) O
. O

Numbers O
in O
bold O
denote O
that O
the O
improvement O
over O
the O
best O
performing O
baseline O
is O
statistically O
signiﬁcant O
( O
t O
- O
test O
with O
p O
- O
value O
< O
0.05 O
) O
. O

5 O
10 O
15 O
Length50607080Session O
Accuracy B-MetricName
BERT B-MethodName
SA B-MethodName
- I-MethodName
BERT I-MethodName
MPC B-MethodName
- I-MethodName
BERT I-MethodName
( O
a O
) O
Addressee B-TaskName
recognition I-TaskName
5 O
10 O
15 O
Length556065Utterance O
Preision O
BERT B-MethodName
SA B-MethodName
- I-MethodName
BERT I-MethodName
MPC B-MethodName
- I-MethodName
BERT I-MethodName
( O
b O
) O
Speaker B-TaskName
identiﬁcation I-TaskName
5 O
10 O
15 O
Length545658606264Response O
Recall O
BERT B-MethodName
SA B-MethodName
- I-MethodName
BERT I-MethodName
MPC B-MethodName
- I-MethodName
BERT I-MethodName
( O
c O
) O
Response B-TaskName
selection I-TaskName
Figure O
3 O
: O
Performance O
of O
models O
under O
different O
session O
lengths O
on O
the O
test O
sets O
of O
Ouchi O
and O
Tsuboi O
( O
2016 O
) O
on O
the O
tasks O
of O
( O
a O
) O
addressee B-TaskName
recognition I-TaskName
, O
( O
b O
) O
speaker B-TaskName
identiﬁcation I-TaskName
and O
( O
c O
) O
response B-TaskName
selection I-TaskName
. O

focusing O
on O
the O
interlocutor O
structures O
. O

5.5 O
Discussions O
Figure O
3 O
illustrates O
how O
the O
performance O
of O
BERT B-MethodName
, O
SA B-MethodName
- I-MethodName
BERT I-MethodName
and O
MPC B-MethodName
- I-MethodName
BERT I-MethodName
changed O
with O
respect O
to O
different O
session O
lengths O
on O
the O
test O
sets O
of O
Ouchi O
and O
Tsuboi O
( O
2016 O
) O
. O

It O
can O
be O
seen O
that O
the O
performance O
of O
addressee B-TaskName
recognition I-TaskName
and O
speaker B-TaskName
identiﬁcation I-TaskName
dropped O
as O
the O
session O
length O
increased O
. O

The O
reason O
might O
be O
that O
longer O
sessions O
always O
contain O
more O
interlocutors O
which O
increase O
the O
difﬁculties O
of O
predicting O
interlocutors O
. O

Meanwhile O
, O
the O
performance O
of O
response B-TaskName
selection I-TaskName
was O
signiﬁcantly O
improved O
as O
the O
session O
length O
increased O
. O

It O
can O
be O
attributed O
to O
that O
longer O
sessions O
enrich O
the O
representations O
of O
contexts O
with O
more O
details O
which O
beneﬁt O
response O
selection O
. O

Furthermore O
, O
as O
the O
session O
length O
increased O
, O
the O
performance O
of O
MPC B-MethodName
- I-MethodName
BERT I-MethodName
dropped O
more O
slightly O
than O
that O
of O
SA B-MethodName
- I-MethodName
BERT I-MethodName
on O
addressee B-TaskName
recognition I-TaskName
andspeaker B-TaskName
identiﬁcation I-TaskName
, O
and O
the O
R B-MetricName
10@1gap I-MetricName
between O
MPC B-MethodName
- I-MethodName
BERT I-MethodName
and O
SA B-MethodName
- I-MethodName
BERT I-MethodName
on O
response B-TaskName
selection I-TaskName
enlarged O
from O
2.71 B-MetricValue
% I-MetricValue
to O
3.22 B-MetricValue
% I-MetricValue
. O

These O
results O
imply O
the O
superiority O
of O
MPC B-MethodName
- I-MethodName
BERT I-MethodName
over O
SA B-MethodName
- I-MethodName
BERT I-MethodName
on O
modeling O
long O
MPCs O
with O
complicated O
structures O
. O

6 O
Conclusion O
In O
this O
paper O
, O
we O
present O
MPC B-MethodName
- I-MethodName
BERT I-MethodName
, O
a O
pre O
- O
trained O
language O
model O
with O
ﬁve O
self O
- O
supervised O
tasks O
for O
MPC O
understanding O
. O

These O
tasks O
jointly O
learn O
who O
says O
what O
towhom O
in O
MPCs O
. O

Experimental O
results O
on O
three O
downstream O
tasks O
show O
that O
MPC B-MethodName
- I-MethodName
BERT I-MethodName
outperforms O
previous O
methods O
by O
large O
margins O
and O
achieves O
new O
state O
- O
of O
- O
the O
- O
art O
performance O
on O
two O
benchmarks O
. O

Acknowledgments O
We O
thank O
anonymous O
reviewers O
for O
their O
valuable O
comments.3691References O
Mart O
´ O
ın O
Abadi O
, O
Paul O
Barham O
, O
Jianmin O
Chen O
, O
Zhifeng O
Chen O
, O
Andy O
Davis O
, O
Jeffrey O
Dean O
, O
Matthieu O
Devin O
, O
Sanjay O
Ghemawat O
, O
Geoffrey O
Irving O
, O
Michael O
Isard O
, O
Manjunath O
Kudlur O
, O
Josh O
Levenberg O
, O
Rajat O
Monga O
, O
Sherry O
Moore O
, O
Derek O
Gordon O
Murray O
, O
Benoit O
Steiner O
, O
Paul O
A. O
Tucker O
, O
Vijay O
Vasudevan O
, O
Pete O
Warden O
, O
Martin O
Wicke O
, O
Yuan O
Yu O
, O
and O
Xiaoqiang O
Zheng O
. O
2016 O
. O

Tensorﬂow O
: O
A O
system O
for O
large O
- O
scale O
machine O
learning O
. O

In O
12th O
USENIX O
Symposium O
on O
Operating O
Systems O
Design O
and O
Implementation O
, O
OSDI O
2016 O
, O
Savannah O
, O
GA O
, O
USA O
, O
November O
2 O
- O
4 O
, O
2016 O
. O
, O
pages O
265–283 O
. O

Jacob O
Devlin O
, O
Ming O
- O
Wei O
Chang O
, O
Kenton O
Lee O
, O
and O
Kristina O
Toutanova O
. O
2019 O
. O

BERT B-MethodName
: O
pre O
- O
training O
of O
deep O
bidirectional O
transformers O
for O
language O
understanding O
. O

In O
Proceedings O
of O
the O
2019 O
Conference O
of O
the O
North O
American O
Chapter O
of O
the O
Association O
for O
Computational O
Linguistics O
: O
Human O
Language O
Technologies O
, O
NAACL O
- O
HLT O
2019 O
, O
Minneapolis O
, O
MN O
, O
USA O
, O
June O
2 O
- O
7 O
, O
2019 O
, O
Volume O
1 O
( O
Long O
and O
Short O
Papers O
) O
, O
pages O
4171–4186 O
. O
Jia O
- O
Chen O
Gu O
, O
Tianda O
Li O
, O
Quan O
Liu O
, O
Zhen O
- O
Hua O
Ling O
, O
Zhiming O
Su O
, O
Si O
Wei O
, O
and O
Xiaodan O
Zhu O
. O
2020 O
. O

Speaker O
- O
aware O
BERT B-MethodName
for O
multi O
- O
turn O
response O
selection O
in O
retrieval O
- O
based O
chatbots O
. O

In O
CIKM O
’ O
20 O
: O
The O
29th O
ACM O
International O
Conference O
on O
Information O
and O
Knowledge O
Management O
, O
Virtual O
Event O
, O
Ireland O
, O
October O
19 O
- O
23 O
, O
2020 O
, O
pages O
2041 O
– O
2044 O
. O

Jia O
- O
Chen O
Gu O
, O
Zhen O
- O
Hua O
Ling O
, O
and O
Quan O
Liu O
. O
2019a O
. O

Interactive O
matching O
network O
for O
multi O
- O
turn O
response O
selection O
in O
retrieval O
- O
based O
chatbots O
. O

In O
Proceedings O
of O
the O
28th O
ACM O
International O
Conference O
on O
Information O
and O
Knowledge O
Management O
, O
CIKM O
2019 O
, O
Beijing O
, O
China O
, O
November O
3 O
- O
7 O
, O
2019 O
, O
pages O
2321–2324 O
. O
Jia O
- O
Chen O
Gu O
, O
Zhen O
- O
Hua O
Ling O
, O
Xiaodan O
Zhu O
, O
and O
Quan O
Liu O
. O

2019b O
. O

Dually O
interactive O
matching O
network O
for O
personalized O
response O
selection O
in O
retrieval O
- O
based O
chatbots O
. O

In O
Proceedings O
of O
the O
2019 O
Conference O
on O
Empirical O
Methods O
in O
Natural O
Language O
Processing O
and O
the O
9th O
International O
Joint O
Conference O
on O
Natural O
Language O
Processing O
, O
EMNLP O
- O
IJCNLP O
2019 O
, O
Hong O
Kong O
, O
China O
, O
November O
3 O
- O
7 O
, O
2019 O
, O
pages O
1845–1854 O
. O

Association O
for O
Computational O
Linguistics O
. O

Suchin O
Gururangan O
, O
Ana O
Marasovic O
, O
Swabha O
Swayamdipta O
, O
Kyle O
Lo O
, O
Iz O
Beltagy O
, O
Doug O
Downey O
, O
and O
Noah O
A. O
Smith O
. O

2020 O
. O

Do O
n’t O
stop O
pretraining O
: O
Adapt O
language O
models O
to O
domains O
and O
tasks O
. O

In O
Proceedings O
of O
the O
58th O
Annual O
Meeting O
of O
the O
Association O
for O
Computational O
Linguistics O
, O
ACL O
2020 O
, O
Online O
, O
July O
5 O
- O
10 O
, O
2020 O
, O
pages O
8342–8360 O
. O

Dan O
Hendrycks O
and O
Kevin O
Gimpel O
. O

2016 O
. O

Bridging O
nonlinearities O
and O
stochastic O
regularizers O
with O
gaussian O
error O
linear O
units O
. O

CoRR O
, O
abs/1606.08415.Wenpeng O
Hu O
, O
Zhangming O
Chan O
, O
Bing O
Liu O
, O
Dongyan O
Zhao O
, O
Jinwen O
Ma O
, O
and O
Rui O
Yan O
. O
2019 O
. O

GSN O
: O
A O
graph O
- O
structured O
network O
for O
multi O
- O
party O
dialogues O
. O

InProceedings O
of O
the O
Twenty O
- O
Eighth O
International O
Joint O
Conference O
on O
Artiﬁcial O
Intelligence O
, O
IJCAI O
2019 O
, O
Macao O
, O
China O
, O
August O
10 O
- O
16 O
, O
2019 O
, O
pages O
5010–5016 O
. O

Diederik O
P. O
Kingma O
and O
Jimmy O
Ba O
. O
2015 O
. O

Adam O
: O
A O
method O
for O
stochastic O
optimization O
. O

In O
3rd O
International O
Conference O
on O
Learning O
Representations O
, O
ICLR O
2015 O
, O
San O
Diego O
, O
CA O
, O
USA O
, O
May O
7 O
- O
9 O
, O
2015 O
, O
Conference O
Track O
Proceedings O
. O

Ran O
Le O
, O
Wenpeng O
Hu O
, O
Mingyue O
Shang O
, O
Zhenjun O
You O
, O
Lidong O
Bing O
, O
Dongyan O
Zhao O
, O
and O
Rui O
Yan O
. O
2019 O
. O

Who O
is O
speaking O
to O
whom O
? O

learning O
to O
identify O
utterance O
addressee O
in O
multi O
- O
party O
conversations O
. O

In O
Proceedings O
of O
the O
2019 O
Conference O
on O
Empirical O
Methods O
in O
Natural O
Language O
Processing O
and O
the O
9th O
International O
Joint O
Conference O
on O
Natural O
Language O
Processing O
, O
EMNLP O
- O
IJCNLP O
2019 O
, O
Hong O
Kong O
, O
China O
, O
November O
3 O
- O
7 O
, O
2019 O
, O
pages O
1909 O
– O
1919 O
. O

Ryan O
Lowe O
, O
Nissan O
Pow O
, O
Iulian O
Serban O
, O
and O
Joelle O
Pineau O
. O
2015 O
. O

The O
ubuntu O
dialogue O
corpus O
: O
A O
large O
dataset O
for O
research O
in O
unstructured O
multi O
- O
turn O
dialogue O
systems O
. O

In O
Proceedings O
of O
the O
SIGDIAL O
2015 O
Conference O
, O
The O
16th O
Annual O
Meeting O
of O
the O
Special O
Interest O
Group O
on O
Discourse O
and O
Dialogue O
, O
2 O
- O
4 O
September O
2015 O
, O
Prague O
, O
Czech O
Republic O
, O
pages O
285–294 O
. O

Zhao O
Meng O
, O
Lili O
Mou O
, O
and O
Zhi O
Jin O
. O

2018 O
. O

Towards O
neural O
speaker O
modeling O
in O
multi O
- O
party O
conversation O
: O
The O
task O
, O
dataset O
, O
and O
models O
. O

In O
Proceedings O
of O
the O
Eleventh O
International O
Conference O
on O
Language O
Resources O
and O
Evaluation O
, O
LREC O
2018 O
, O
Miyazaki O
, O
Japan O
, O
May O
7 O
- O
12 O
, O
2018 O
. O

European O
Language O
Resources O
Association O
( O
ELRA O
) O
. O

Hiroki O
Ouchi O
and O
Yuta O
Tsuboi O
. O

2016 O
. O

Addressee O
and O
response O
selection O
for O
multi O
- O
party O
conversation O
. O

In O
Proceedings O
of O
the O
2016 O
Conference O
on O
Empirical O
Methods O
in O
Natural O
Language O
Processing O
, O
EMNLP O
2016 O
, O
Austin O
, O
Texas O
, O
USA O
, O
November O
1 O
- O
4 O
, O
2016 O
, O
pages O
2133–2143 O
. O
Iulian O
Vlad O
Serban O
, O
Alessandro O
Sordoni O
, O
Yoshua O
Bengio O
, O
Aaron O
C. O
Courville O
, O
and O
Joelle O
Pineau O
. O
2016 O
. O

Building O
end O
- O
to O
- O
end O
dialogue O
systems O
using O
generative O
hierarchical O
neural O
network O
models O
. O

In O
Proceedings O
of O
the O
Thirtieth O
AAAI O
Conference O
on O
Artiﬁcial O
Intelligence O
, O
February O
12 O
- O
17 O
, O
2016 O
, O
Phoenix O
, O
Arizona O
, O
USA O
, O
pages O
3776–3784 O
. O
Iulian O
Vlad O
Serban O
, O
Alessandro O
Sordoni O
, O
Ryan O
Lowe O
, O
Laurent O
Charlin O
, O
Joelle O
Pineau O
, O
Aaron O
C. O
Courville O
, O
and O
Yoshua O
Bengio O
. O
2017 O
. O

A O
hierarchical O
latent O
variable O
encoder O
- O
decoder O
model O
for O
generating O
dialogues O
. O

In O
Proceedings O
of O
the O
Thirty O
- O
First O
AAAI O
Conference O
on O
Artiﬁcial O
Intelligence O
, O
February O
4 O
- O
9 O
, O
2017 O
, O
San O
Francisco O
, O
California O
, O
USA O
, O
pages O
3295 O
– O
3301 O
. O

AAAI O
Press.3692Lifeng O
Shang O
, O
Zhengdong O
Lu O
, O
and O
Hang O
Li O
. O
2015 O
. O

Neural O
responding O
machine O
for O
short O
- O
text O
conversation O
. O

In O
Proceedings O
of O
the O
53rd O
Annual O
Meeting O
of O
the O
Association O
for O
Computational O
Linguistics O
and O
the O
7th O
International O
Joint O
Conference O
on O
Natural O
Language O
Processing O
of O
the O
Asian O
Federation O
of O
Natural O
Language O
Processing O
, O
ACL O
2015 O
, O
July O
2631 O
, O
2015 O
, O
Beijing O
, O
China O
, O
Volume O
1 O
: O
Long O
Papers O
, O
pages O
1577–1586 O
. O

Chongyang O
Tao O
, O
Wei O
Wu O
, O
Can O
Xu O
, O
Wenpeng O
Hu O
, O
Dongyan O
Zhao O
, O
and O
Rui O
Yan O
. O
2019a O
. O

Multirepresentation O
fusion O
network O
for O
multi O
- O
turn O
response O
selection O
in O
retrieval O
- O
based O
chatbots O
. O

In O
Proceedings O
of O
the O
Twelfth O
ACM O
International O
Conference O
on O
Web O
Search O
and O
Data O
Mining O
, O
WSDM O
2019 O
, O
Melbourne O
, O
VIC O
, O
Australia O
, O
February O
11 O
- O
15 O
, O
2019 O
, O
pages O
267–275 O
. O
ACM O
. O

Chongyang O
Tao O
, O
Wei O
Wu O
, O
Can O
Xu O
, O
Wenpeng O
Hu O
, O
Dongyan O
Zhao O
, O
and O
Rui O
Yan O
. O
2019b O
. O

One O
time O
of O
interaction O
may O
not O
be O
enough O
: O
Go O
deep O
with O
an O
interaction O
- O
over O
- O
interaction O
network O
for O
response O
selection O
in O
dialogues O
. O

In O
Proceedings O
of O
the O
57th O
Conference O
of O
the O
Association O
for O
Computational O
Linguistics O
, O
ACL O
2019 O
, O
Florence O
, O
Italy O
, O
July O
28August O
2 O
, O
2019 O
, O
Volume O
1 O
: O
Long O
Papers O
, O
pages O
1 O
– O
11 O
. O

Weishi O
Wang O
, O
Steven O
C. O
H. O
Hoi O
, O
and O
Shaﬁq O
R. O
Joty O
. O

2020 O
. O

Response O
selection O
for O
multi O
- O
party O
conversations O
with O
dynamic O
topic O
tracking O
. O

In O
Proceedings O
of O
the O
2020 O
Conference O
on O
Empirical O
Methods O
in O
Natural O
Language O
Processing O
, O
EMNLP O
2020 O
, O
Online O
, O
November O
16 O
- O
20 O
, O
2020 O
, O
pages O
6581 O
– O
6591 O
. O

Yu O
Wu O
, O
Wei O
Wu O
, O
Chen O
Xing O
, O
Ming O
Zhou O
, O
and O
Zhoujun O
Li O
. O
2017 O
. O

Sequential O
matching O
network O
: O
A O
new O
architecture O
for O
multi O
- O
turn O
response O
selection O
in O
retrieval O
- O
based O
chatbots O
. O

In O
Proceedings O
of O
the O
55th O
Annual O
Meeting O
of O
the O
Association O
for O
Computational O
Linguistics O
, O
ACL O
2017 O
, O
Vancouver O
, O
Canada O
, O
July O
30 O
- O
August O
4 O
, O
Volume O
1 O
: O
Long O
Papers O
, O
pages O
496–505 O
. O

Rui O
Zhang O
, O
Honglak O
Lee O
, O
Lazaros O
Polymenakos O
, O
and O
Dragomir O
R. O
Radev O
. O

2018a O
. O

Addressee O
and O
response O
selection O
in O
multi O
- O
party O
conversations O
with O
speaker O
interaction O
rnns O
. O

In O
Proceedings O
of O
the O
ThirtySecond O
AAAI O
Conference O
on O
Artiﬁcial O
Intelligence O
, O
( O
AAAI-18 O
) O
, O
the O
30th O
innovative O
Applications O
of O
Artiﬁcial O
Intelligence O
( O
IAAI-18 O
) O
, O
and O
the O
8th O
AAAI O
Symposium O
on O
Educational O
Advances O
in O
Artiﬁcial O
Intelligence O
( O
EAAI-18 O
) O
, O
New O
Orleans O
, O
Louisiana O
, O
USA O
, O
February O
2 O
- O
7 O
, O
2018 O
, O
pages O
5690–5697 O
. O

Yizhe O
Zhang O
, O
Michel O
Galley O
, O
Jianfeng O
Gao O
, O
Zhe O
Gan O
, O
Xiujun O
Li O
, O
Chris O
Brockett O
, O
and O
Bill O
Dolan O
. O

2018b O
. O

Generating O
informative O
and O
diverse O
conversational O
responses O
via O
adversarial O
information O
maximization O
. O

InAdvances O
in O
Neural O
Information O
Processing O
Systems O
31 O
: O
Annual O
Conference O
on O
Neural O
Information O
Processing O
Systems O
2018 O
, O
NeurIPS O
2018 O
, O
December O
3 O
- O
8 O
, O
2018 O
, O
Montr O
´ O
eal O
, O
Canada O
, O
pages O
1815–1825.Yizhe O
Zhang O
, O
Siqi O
Sun O
, O
Michel O
Galley O
, O
Yen O
- O
Chun O
Chen O
, O
Chris O
Brockett O
, O
Xiang O
Gao O
, O
Jianfeng O
Gao O
, O
Jingjing O
Liu O
, O
and O
Bill O
Dolan O
. O

2020 O
. O

DIALOGPT O
: O
Large O
- O
scale O
generative O
pre O
- O
training O
for O
conversational O
response O
generation O
. O

In O
Proceedings O
of O
the O
58th O
Annual O
Meeting O
of O
the O
Association O
for O
Computational O
Linguistics O
: O
System O
Demonstrations O
, O
ACL O
2020 O
, O
Online O
, O
July O
5 O
- O
10 O
, O
2020 O
, O
pages O
270–278 O
. O

Association O
for O
Computational O
Linguistics O
. O

Xiangyang O
Zhou O
, O
Lu O
Li O
, O
Daxiang O
Dong O
, O
Yi O
Liu O
, O
Ying O
Chen O
, O
Wayne O
Xin O
Zhao O
, O
Dianhai O
Yu O
, O
and O
Hua O
Wu O
. O

2018 O
. O

Multi O
- O
turn O
response O
selection O
for O
chatbots O
with O
deep O
attention O
matching O
network O
. O

In O
Proceedings O
of O
the O
56th O
Annual O
Meeting O
of O
the O
Association O
for O
Computational O
Linguistics O
, O
ACL O
2018 O
, O
Melbourne O
, O
Australia O
, O
July O
15 O
- O
20 O
, O
2018 O
, O
Volume O
1 O
: O
Long O
Papers O
, O
pages O
1118–1127 O
. O

