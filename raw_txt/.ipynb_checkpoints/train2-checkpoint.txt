Would O
you O
Rather O
? O

A O
New O
Benchmark O
for O
Learning O
Machine O
Alignment O
with O
Cultural O
Values O
and O
Social B-TaskName
Preferences I-TaskName
yYi O
Tay,[Donovan O
Ong,]Jie O
Fu O
, O
yAlvin O
Chan,[Nancy O

F. O
Chen O
 O
 O
Luu O
Anh O
Tuan,]zChristopher O
Pal O
yNanyang O
Technological O
University O
, O
Singapore O
] O
Polytechnique O
Montreal O
, O
Mila O
, O
zCanada O
CIFAR O
AI O
Chair O
[ O
A*STAR O
, O
Singapore,MIT O
CSAIL O
, O
 O
VinAI O
Research O
ytay017@gmail.com O
, O
ongyl@i2r.a-star.edu.sg O
Abstract O
Understanding O
human O
preferences O
, O
along O
with O
cultural O
and O
social O
nuances O
, O
lives O
at O
the O
heart O
of O
natural B-TaskName
language I-TaskName
understanding I-TaskName
. O

Concretely O
, O
we O
present O
a O
new O
task O
and O
corpus O
for O
learning O
alignments O
between O
machine O
and O
human O
preferences O
. O

Our O
newly O
introduced O
problem O
is O
concerned O
with O
predicting B-TaskName
the I-TaskName
preferable I-TaskName
options I-TaskName
from O
two O
sentences O
describing O
scenarios O
that O
may O
involve O
social O
and O
cultural O
situations O
. O

Our O
problem O
is O
framed O
as O
a O
natural B-TaskName
language I-TaskName
inference I-TaskName
task O
with O
crowd O
- O
sourced O
preference O
votes O
by O
human O
players O
, O
obtained O
from O
a O
gamiÔ¨Åed O
voting O
platform O
. O

We O
benchmark O
several O
state O
- O
of O
- O
the O
- O
art O
neural O
models O
, O
along O
with O
BERT B-MethodName
and O
friends O
on O
this O
task O
. O

Our O
experimental O
results O
show O
that O
current O
state O
- O
ofthe O
- O
art O
NLP O
models O
still O
leave O
much O
room O
for O
improvement O
. O

1 O
Introduction O
The O
ability O
to O
understanding O
social O
nuances O
and O
human O
preferences O
is O
central O
to O
natural B-TaskName
language I-TaskName
understanding I-TaskName
. O

This O
also O
enables O
better O
alignment O
of O
machine O
learning O
models O
with O
human O
values O
, O
eventually O
leading O
to O
better O
human O
- O
compatible O
AI O
applications O
( O
Peterson O
et O
al O
. O
, O
2019 O
; O
Leslie O
, O
2019 O
; O
Rosenfeld O
and O
Kraus O
, O
2018 O
; O
Amodei O
et O
al O
. O
, O
2016 O
; O
Russell O
and O
Norvig O
, O
2016 O
) O
. O

There O
exist O
a O
plethora O
of O
work O
on O
studying O
optimal O
decision O
- O
making O
under O
a O
variety O
of O
situations O
( O
Edwards O
, O
1954 O
; O
Bottom O
, O
2004 O
; O
Plonsky O
et O
al O
. O
, O
2019 O
; O
Peterson O
et O
al O
. O
, O
2019 O
) O
. O

On O
the O
other O
hand O
, O
cognitive O
models O
of O
human O
decision O
- O
making O
are O
usually O
based O
on O
small O
datasets O
( O
Peterson O
et O
al O
. O
, O
2019 O
) O
. O

Furthermore O
, O
these O
studies O
tend O
to O
only O
consider O
individuals O
in O
isolation O
. O

In O
contrast O
, O
we O
investigate O
the O
inÔ¨Çuence O
of O
cultural O
and O
social O
nuances O
for O
choice O
prediction O
at O
scale O
. O

In O
other O
words O
, O
we O
study O
the O
social B-TaskName
preference I-TaskName
as O
a O
whole O
, O
First O
two O
authors O
contributed O
equallynot O
those O
of O
an O
individual O
in O
isolation O
, O
which O
is O
arguably O
more O
challenging O
and O
largely O
unexplored O
. O

In O
this O
work O
, O
we O
propose O
a O
new O
benchmark O
dataset O
with O
a O
large O
number O
of O
200k O
data O
points O
, O
Machine O
Alignment O
with O
Cultural O
values O
and O
Social B-TaskName
preferences I-TaskName
( O
MACS B-DatasetName
) O
, O
for O
learning O
AI O
alignment O
with O
humans O
. O

Our O
dataset O
is O
based O
on O
a O
popular O
gamiÔ¨Åed O
voting O
platform O
, O
namely O
the O
game O
of O
‚Äò O
would O
you O
rather O
? O
‚Äô O
. O

In O
this O
game O
, O
participants O
are O
given O
two O
choices O
and O
vote O
for O
the O
more O
preferable O
option O
. O

Examples O
from O
our O
dataset O
can O
be O
found O
at O
Table O
1 O
. O

To O
the O
best O
of O
our O
knowledge O
, O
our O
work O
is O
the O
Ô¨Årst O
work O
to O
incorporate O
voting O
- O
based O
language O
games O
as O
a O
language O
understanding O
benchmark O
. O

In O
many O
ways O
, O
our O
benchmark O
dataset O
is O
reminiscent O
of O
the O
natural B-TaskName
language I-TaskName
inference I-TaskName
problem O
( O
MacCartney O
, O
2009 O
; O
Bowman O
et O
al O
. O
, O
2015 O
) O
, O
social O
commonsense O
reasoning O
( O
Sap O
et O
al O
. O
, O
2019 O
) O
or O
other O
natural B-TaskName
language I-TaskName
understanding I-TaskName
problems O
( O
Wang O
et O
al O
. O
, O
2018 O
; O
Zellers O
et O
al O
. O
, O
2018 O
) O
. O

To O
this O
end O
, O
our O
problem O
is O
framed O
in O
a O
way O
that O
enables O
convenient O
benchmarking O
of O
existing O
state O
- O
of O
- O
the O
- O
art O
NLU O
models O
such O
as O
BERT B-MethodName
( O
Devlin O
et O
al O
. O
, O
2018 O
) O
or O
RoBERTa B-MethodName
( O
Liu O
et O
al O
. O
, O
2019 O
) O
. O

That O
said O
, O
unlike O
many O
NLU O
datasets O
that O
rely O
on O
few O
annotators O
, O
the O
key O
differentiator O
lies O
in O
the O
fact O
that O
our O
dataset O
aggregates O
across O
hundreds O
or O
thousands O
and O
beyond O
for O
each O
data O
point O
. O

Options O
are O
also O
crowd O
- O
sourced O
and O
gamiÔ¨Åed O
which O
may O
encourage O
less O
monotonic O
samples O
, O
ie O
. O
, O
encouraging O
players O
to O
come O
up O
with O
questionss O
that O
are O
difÔ¨Åcult O
for O
other O
players O
. O

Additionally O
, O
our O
dataset O
comprises O
of O
country O
- O
level O
statistics O
, O
which O
enable O
us O
to O
perform O
cultural O
- O
level O
prediction O
of O
preferences O
. O

Our O
Contributions O
All O
in O
all O
, O
the O
prime O
contribution O
of O
this O
work O
is O
as O
follows O
: O
We O
propose O
a O
new O
NLU O
benchmark O
based O
onan O
online O
gamiÔ¨Åed O
voting O
platform O
. O

We O
propose O
several O
ways O
to O
formulate O
the O
problem O
, O
including O
absolute O
and O
relative O
preference B-TaskName
prediction I-TaskName
. O

We O
also O
introduce O
a O
cultural O
- O
level O
NLU O
problem O
formulation O
. O

We O
investigate O
state O
- O
of O
- O
the O
- O
art O
NLU O
models O
such O
as O
BERT B-MethodName
( O
Devlin O
et O
al O
. O
, O
2018 O
) O
, O
RobERTA B-MethodName
( O
Liu O
et O
al O
. O
, O
2019 O
) O
and O
XLNET B-MethodName
( O
Yang O
et O
al O
. O
, O
2019 O
) O
on O
this O
dataset O
. O

Empirical O
results O
suggests O
that O
our O
benchmark O
is O
reasonably O
difÔ¨Åcult O
and O
there O
is O
a O
huge O
room O
for O
improvement O
. O

2 O
Learning O
Alignment O
with O
Human O
Preferences O
This O
section O
describes O
the O
proposed O
dataset O
and O
problem O
formulation O
. O

2.1 O
Dataset O
We O
look O
to O
crowdsourcing O
platforms O
to O
construct O
our O
dataset O
. O

Our O
dataset O
is O
constructed O
from O
https://www.rrrather.com/ O
, O
an O
online O
platform1for O
gamiÔ¨Åed O
voting O
. O

The O
platform O
is O
modeled O
after O
the O
famous O
internet O
game O
- O
would O
you O
rather O
? O

, O
which O
pits O
two O
supposedly O
comparable O
choices O
together O
. O

Whenever O
a O
player O
votes O
, O
their O
vote O
is O
recorded O
in O
the O
system O
. O

Players O
generally O
vote O
to O
see O
how O
well O
their O
vote O
aligns O
with O
the O
majority O
and O
consensus O
with O
everyone O
else O
. O

We O
provide O
samples O
of O
the O
problem O
space O
in O
Table O
1 O
. O

We O
crawled O
data O
from O
the O
said O
platform O
and O
Ô¨Åltered O
away O
posts O
with O
less O
than O
500total O
votes O
. O

In O
total O
, O
we O
amassed O
194,525 O
data O
points O
, O
which O
we O
split O
into O
train O
/ O
dev O
/ O
test O
splits O
in O
an O
80/10/10 O
fashion O
. O

Dataset O
statistics O
are O
provided O
in O
Table O
2 O
. O
Train O
Dev O
Test O
Total O
Data O
155,621 O
19,452 O
19,452 O
194,525 O
` O
max O
678 O
351 O
298 O
` O
mean O
8 O
8 O
8 O
` O
min O
1 O
2 O
2 O
Table O
2 O
: O
Dataset O
statistics O
of O
the O
MACS B-DatasetName
dataset O
. O

2.2 O
Why O
is O
this O
interesting O
? O

This O
section O
outlines O
the O
beneÔ¨Åts O
of O
our O
proposed O
dataset O
as O
a O
language O
understanding O
benchmark O
. O

1The O
authors O
have O
obtained O
written O
permission O
from O
the O
owner O
of O
the O
platform O
to O
crawl O
and O
use O
their O
data O
for O
academic O
research O
. O

The O
questions O
, O
answers O
or O
discussions O
do O
not O
represent O
opinions O
of O
the O
authors O
in O
this O
paper.(1 O
) O
Understanding O
before O
Interaction O
. O

In O
our O
dataset O
and O
problem O
formulation O
, O
complex O
understanding O
of O
each O
option O
text O
is O
often O
required O
Ô¨Årst O
before O
modeling O
the O
relative O
preference O
between O
two O
options O
. O

This O
is O
unlike O
NLI O
or O
questionanswering O
based O
NLU O
benchmarks O
, O
where O
matching O
signals O
can O
be O
used O
to O
predict O
the O
outcome O
easily O
. O

In O
our O
dataset O
and O
task O
, O
it O
is O
imperative O
that O
any O
form O
of O
word O
overlap O
can O
be O
hardly O
used O
to O
determine O
the O
outcome O
. O

( O
2 O
) O
A O
good O
coverage O
of O
social B-TaskName
preferences I-TaskName
. O

Upon O
closer O
inspection O
of O
our O
proposed O
benchmark O
, O
we O
Ô¨Ånd O
there O
is O
a O
good O
representation O
of O
samples O
which O
cover O
social O
and O
cultural O
themes O
. O

Social B-TaskName
preferences I-TaskName
( O
such O
as O
the O
preference O
of O
brands O
) O
are O
captured O
in O
samples O
such O
as O
example O
( O
6 O
) O
. O

( O
3 O
) O
Completely O
natural O
. O

Our O
MACS B-DatasetName
dataset O
completely O
exists O
in O
the O
wild O
naturally O
. O

This O
is O
unlike O
datasets O
that O
have O
to O
be O
annotated O
by O
mechanical O
turkers O
or O
paid O
raters O
. O

In O
general O
, O
there O
is O
a O
lack O
of O
incentives O
for O
turkers O
to O
provide O
highquality O
ratings O
, O
which O
often O
results O
in O
problems O
such O
as O
annotation O
artifacts O
. O

Unlike O
these O
datasets O
, O
our O
MACS B-DatasetName
dataset O
completely O
exists O
in O
the O
wild O
naturally O
. O

The O
choices O
are O
often O
created O
by O
other O
human O
players O
. O

Hence O
, O
in O
the O
spirit O
of O
competitiveness O
, O
this O
means O
that O
the O
data O
is O
meant O
to O
be O
deliberately O
challenging O
. O

Moreover O
, O
there O
are O
at O
least O
500 O
annotators O
for O
each O
sample O
, O
which O
makes O
the O
assigned O
label O
less O
susceptible O
to O
noisy O
raters O
. O

2.3 O
Problem O
Formulation O
Given O
Q(prompt O
) O
, O
two O
sentences O
S1andS2and O
V(:)which O
computes O
the O
absolute O
votes O
to O
each O
option O
, O
we O
explore O
different O
sub O
- O
tasks O
( O
or O
variant O
problem O
formulation O
) O
. O

Predicting B-TaskName
Preference I-TaskName

This O
task O
is O
primarily O
concerned O
with O
predicting O
if O
V(S1 O
) O
> O
V(S2)or O
otherwise O
. O

Intuitively O
, O
if O
a O
model O
is O
able O
to O
solve O
this O
task O
( O
perform O
equivalent O
to O
a O
human O
player O
) O
, O
we O
consider O
it O
to O
have O
some O
fundamental O
understanding O
of O
human O
values O
and O
social B-TaskName
preferences I-TaskName
. O

We O
frame O
this O
task O
in O
two O
ways O
. O

The O
Ô¨Årst O
is O
a O
straightforward O
binary O
classiÔ¨Åcation O
problem O
, O
i.e. O
, O
V(S1 O
) O
> O
V(S2 O
) O
. O

The O
second O
task O
is O
a O
three O
- O
way O
classiÔ¨Åcation O
problem O
with O
a O
third O
class O
predicting O
if O
the O
differencejV(S1) V(S2)jis O
less O
than O
5 O
% O
of O
the O
total O
votes O
. O

In O
short O
, O
this O
means O
that O
two O
options O
are O
almost O
in O
a O
draw O
. O

Prompt O
Option O
A O
Option O
B O
( O
1 O
) O
Would O
you O
rather O
Ô¨Åt O
into O
any O
group O
but O
never O
be O
popular O
only O
Ô¨Åt O
into O
the O
popular O
group O
( O
2 O
) O
Would O
you O
rather O
have O
no O
one O
attend O
yourfuneral O
wedding O
( O
3 O
) O
Would O
you O
rather O
have O
free O
starbucks O
for O
an O
entire O
year O
free O
itunes O
forever O
( O
4 O
) O
Would O
you O
rather O
Look O
unhealthy O
and O
unattractive O
, O
but O
be O
in O
perfect O
health O
. O

Be O
absolutely O
beautiful O
and O
look O
healthy O
, O
but O
be O
in O
extremely O
bad O
health O
. O

( O
5 O
) O
Would O
you O
rather O
Win O
the O
lottery O
Live O
twice O
as O
long O
( O
6 O
) O
Would O
you O
rather O
have O
a O
Mac O
a O
PC O
( O
7 O
) O
Would O
you O
rather O
spend O
the O
daySurÔ¨Ång O
on O
the O
ocean O

SurÔ¨Ång O
the O
Internet O
Table O
1 O
: O
Samples O
from O
our O
MACS B-DatasetName
dataset O
. O

Standard O
Cultural O
Binary O
Three O
- O
way O
Binary O
Three O
- O
way O
Model O
Dev O
Test O
Dev O
Test O
Dev O
Test O
Dev O
Test O
BERT B-MethodName
61.02 O
60.38 O
56.71 O
55.85 O
62.42 O
62.88 O
57.42 O
58.21 O
XLNEt B-MethodName
56.12 O
56.84 O
55.72 O
56.34 O
51.77 O
51.42 O
57.08 O
57.39 O
RoBERTa B-MethodName
64.75 O
64.15 O
61.04 O
61.19 O
64.39 O
64.71 O
59.28 O
61.22 O
Table O
3 O
: O
Experimental O
results O
on O
predicting B-TaskName
preference I-TaskName
( O
standard O
and O
cultural O
) O
with O
BERT B-MethodName
( O
Devlin O
et O
al O
. O
, O
2018 O
) O
, O
XLNEt B-MethodName
( O
Yang O
et O
al O
. O
, O
2019 O
) O
and O
RoBERTa B-MethodName
( O
Liu O
et O
al O
. O
, O
2019 O
) O
on O
MACS B-DatasetName
dataset O
. O

Predicting B-TaskName
Cultural I-TaskName
Preferences I-TaskName
We O
consider O
a O
variant O
of O
the O
preference B-TaskName
prediction I-TaskName
problem O
. O

Our O
MACS B-DatasetName
dataset O
has O
culture O
- O
level O
preference O
votes O
which O
are O
the O
voting O
scores O
with O
respect O
to O
a O
particular O
cultural O
demographic O
. O

We O
extend O
the O
same O
setting O
as O
Task O
1 O
by O
requiring O
the O
model O
to O
produce O
culture O
- O
level O
predictions O
. O

In O
order O
to O
do O
this O
, O
we O
prepend O
the O
input O
sentence O
with O
a O
culture O
embedding O
token O
. O

For O
example O
, O
Input O
= O

[ O
Culture O
] O

+ O
[ O
Choice O
A O
] O

+ O
[ O
Sep O
] O
+ O

[ O
Choice O
B O
] O
. O

The O
task O
is O
identical O
, O
predicting O
the O
greater O
of O
Choice O
A O
OR O
Choice O
B O
, O
with O
respect O
to O
the O
cultural O
ground O
truth O
. O

The O
dataset O
is O
augmented O
at O
the O
culture O
level O
and O
the O
same O
example O
is O
duplicated O
for O
each O
culture O
, O
e.g. O
, O
we O
duplicate O
the O
sample O
for O
countries O
‚Äô O
USA O
‚Äô O
and O
‚Äô O
Europe O
‚Äô O
. O

We O
consider O
only O
culturelevel O
votes O
with O
a O
threshold O
above O
25votes O
in O
the O
dataset O
for O
train O
/ O
dev O
/ O
test O
sets O
. O

Predicting B-TaskName
Relative I-TaskName
Preference I-TaskName
The O
third O
variant O
is O
a O
Ô¨Åne O
- O
grained O
regression O
task O
where O
we O
want O
to O
identify O
if O
our O
model O
is O
able O
to O
learn O
the O
extent O
of O
preference O
given O
by O
human O
players O
. O

This O
problem O
is O
framed O
as O
a O
regression O
problem O
that O
is O
normalized O
from O
[ O
0;1]with O
respect O
to O
the O
total O
number O
of O
votes O
in O
the O
data O
point O
3 O
Experiments O
This O
section O
outlines O
our O
experimental O
setup O
and O
results.3.1 O
Experimental O
Setup O
We O
implement O
and O
run O
several O
models O
on O
this O
dataset O
. O

( O
1 O
) O
BERT B-MethodName
( O
Devlin O
et O
al O
. O
, O
2018 O
) O
- O

Deep O
Bidirectional O
Transformers O
is O
the O
state O
- O
of O
- O
the O
- O
art O
pretrained O
transformer O
model O
for O
a O
wide O
range O
of O
NLP O
tasks O
. O

( O
2 O
) O
XLNet B-MethodName
( O
Yang O
et O
al O
. O
, O
2019 O
) O
is O
a O
large O
pretrained O
model O
based O
on O
Transformer O
- O
XL O
. O

( O
3 O
) O
RoBertA B-MethodName
( O
Liu O
et O
al O
. O
, O
2019 O
) O
is O
a O
robustly O
optimized O
improvement O
over O
the O
vanilla O
BERT B-MethodName
model O
. O

All O
models O
were O
run O
using O
the O
Ô¨Ånetune O
methodology O
using O
the O
standard O
Pytorch O
Huggingface2repository O
. O

We O
train O
( O
Ô¨Ånetune O
) O
all O
models O
for O
3 B-HyperparameterValue
epochs B-HyperparameterName
using O
the O
default B-HyperparameterName
hyperparameters I-HyperparameterName
.. O

Metrics O

The O
evaluation O
metrics O
for O
classiÔ¨Åcation O
tasks O
is O
the O
standard O
accuracy B-MetricName
score O
. O

For O
regression O
tasks O
, O
we O
use O
the O
correlation B-MetricName
, O
Pearson B-MetricName
, O
and O
Spearman B-MetricName
metrics O
. O

3.2 O
Experimental O
Results O
Table O
3 O
reports O
our O
results O
on O
binary O
and O
three O
- O
way O
classiÔ¨Åcation O
on O
the O
MACS B-DatasetName
dataset O
. O

In O
general O
, O
we O
Ô¨Ånd O
that O
RoBERTa B-MethodName
performs O
the O
best O
. O

However O
, O
in O
most O
cases O
, O
the O
performance O
of O
all O
three O
models O
still O
leaves O
a O
lot O
to O
be O
desired O
. O

An O
accuracy B-MetricName
of60%+ B-MetricValue
shows O
that O
state O
- O
of O
- O
the O
- O
art O
models O
still O
struggle O
at O
this O
task O
. O

On O
the O
other O
hand O
, O
results O
on O
regression O
task O
are O
also O
similarly O
lacklustre O
, O
and O
2https://github.com/huggingface/ O
transformersDev O
Test O
Model O
Correlation B-MetricName
Pearson B-MetricName
Spearman B-MetricName
Correlation B-MetricName
Pearson B-MetricName
Spearman B-MetricName
BERT B-MethodName
0.234 O
0.256 O

0.214 O
0.229 O
0.250 O
0.208 O
XLNEt B-MethodName
0.225 O
0.243 O
0.206 O
0.228 O
0.250 O
0.206 O
RoBERTa B-MethodName
0.258 O
0.279 O
0.236 O
0.256 O
0.278 O
0.235 O
Table O
4 O
: O
Experimental O
results O
on O
predicting B-TaskName
relative I-TaskName
preference I-TaskName
on O
MACS B-DatasetName
dataset O
. O

Prompt O
Option O
A O
Option O
B O
V O
ote O
A O
V O
ote O
B O
Pred O
( O
1 O
) O
Would O
you O
rather O
be O
happy O
and O
with O
friends O
popular O
and O
without O
friends O
95.39 O
% O
4.61 O
% O
7 O
( O
2 O
) O
Would O
you O
rather O
.... O

Own O
a O
self O
reÔ¨Ålling O
fridge O
. O

Have O
a O
self O
cleaning O
bed O

room.74.10 O
% O
25.9 O
% O
7 O
( O
3 O
) O
Which O
art O
style O
do O
you O
preferPhotography O
Poetry O
69.62 O
% O
30.38 O
% O
7 O
( O
4 O
) O
Would O
you O
rather O
Be O
A O
Millionare O
Be O
the O
kindest O
, O
loveing O
most O
talented O
human O
being O
living O
and O
will O
ever O
live47.32 O
% O
52.68 O
% O
3 O
( O
5 O
) O
Would O
you O
rather O
Be O
the O
Ô¨Årst O
to O
invent O
an O
Invisibility O
cloakBe O
the O
Ô¨Årst O
to O
invent O
a O
Teleportation O
device47.32 O
% O
52.68 O
% O
3 O
Table O
5 O
: O
Model O
predictions O
from O
MACS B-DatasetName
dataset O
using O
Ô¨Ånetuned O
BERT B-MethodName
. O
show O
that O
models O
like O
BERT B-MethodName
and O
RoBERTa B-MethodName
are O
unable O
to O
perform O
well O
on O
this O
task O
. O

On O
a O
whole O
, O
it O
is O
good O
to O
note O
that O
RoBERTa B-MethodName
performs O
the O
best O
out O
of O
the O
three O
compared O
models O
. O

Overall O
, O
this O
encourages O
further O
research O
on O
cultural O
and O
social O
commonsense O
reasoning O
in O
the O
current O
state O
- O
of O
- O
the O
- O
art O
in O
natural B-TaskName
language I-TaskName
understanding I-TaskName
. O

All O
in O
all O
, O
we O
hope O
our O
benchmark O
serves O
as O
a O
useful O
tool O
for O
understanding O
the O
social O
capabilities O
of O
these O
models O
. O

3.3 O
Qualitative O
Evaluation O
Table O
5 O
reports O
some O
sample O
of O
our O
model O
outputs O
, O
shedding O
light O
on O
examples O
in O
which O
our O
model O
does O
well O
and O
otherwise O
. O

We O
observe O
that O
the O
model O
often O
gets O
the O
answer O
wrong O
even O
when O
the O
ground O
truth O
is O
overwhelmingly O
swayed O
towards O
one O
side O
. O

On O
the O
other O
hand O
, O
occasionally O
, O
we O
also O
observe O
that O
the O
model O
can O
get O
questionable O
questions O
such O
as O
( O
4 O
) O
and O
( O
5 O
) O
correctly O
even O
despite O
the O
tight O
draw O
between O
human O
voters O
. O

4 O
Conclusion O
We O
propose O
MACS B-DatasetName
( O
Machine B-DatasetName
Alignment I-DatasetName
with I-DatasetName
Cultural I-DatasetName
and I-DatasetName
Social I-DatasetName
Preferences I-DatasetName
) O
, O
a O
new O
benchmark O
dataset O
for O
learning O
machine O
alignment O
with O
human O
cultural O
and O
social B-TaskName
preferences I-TaskName
. O

MACS B-DatasetName
encompasses O
and O
requires O
social O
and O
cultural O
reasoning O
to O
solve O
and O
an O
overall O
holistic O
understanding O
of O
humanity O
. O

It O
is O
designed O
to O
be O
challenging O
where O
state O
- O
of O
- O
the O
- O
art O
NLP O
models O
still O
struggle O
at O
60%.Broader O
Impact O
In O
this O
paper O
, O
we O
are O
not O
promoting O
the O
use O
of O
https://www.rrrather.com/ O
as O
the O
training O
source O
, O
but O
rather O
the O
study O
of O
the O
alignment O
of O
machine O
learning O
models O
with O
social B-TaskName
preference I-TaskName
of O
a O
large O
population O
. O

Unfortunately O
, O
there O
might O
be O
some O
issues O
of O
bias O
, O
fairness O
and O
representation O
due O
to O
the O
curation O
of O
the O
training O
data O
from O
Internet O
, O
which O
might O
lead O
models O
to O
give O
prejudiced O
or O
stereotyped O
outputs O
. O

Evaluating O
bias O
, O
fairness O
and O
representation O
in O
language O
models O
and O
the O
training O
data O
is O
an O
important O
research O
area O
( O
Nadeem O
et O
al O
. O
, O
2020 O
; O
Huang O
et O
al O
. O
, O
2019 O
) O
. O

As O
for O
future O
works O
, O
it O
is O
important O
to O
characterize O
and O
intervene O
biases O
when O
designing O
such O
tasks O
. O

References O
Dario O
Amodei O
, O
Chris O
Olah O
, O
Jacob O
Steinhardt O
, O
Paul O
Christiano O
, O
John O
Schulman O
, O
and O
Dan O
Man O
¬¥ O
e. O
2016 O
. O

Concrete O
problems O
in O
ai O
safety O
. O

arXiv O
preprint O
arXiv:1606.06565 O
. O

William O
P O
Bottom O
. O

2004 O
. O

Heuristics O
and O
biases O
: O
The O
psychology O
of O
intuitive O
judgment O
. O

Samuel O
R O
Bowman O
, O
Gabor O
Angeli O
, O
Christopher O
Potts O
, O
and O
Christopher O
D O
Manning O
. O

2015 O
. O

A O
large O
annotated O
corpus O
for O
learning O
natural B-TaskName
language I-TaskName
inference I-TaskName
. O

arXiv O
preprint O
arXiv:1508.05326 O
. O

Jacob O
Devlin O
, O
Ming O
- O
Wei O
Chang O
, O
Kenton O
Lee O
, O
and O
Kristina O
Toutanova O
. O
2018 O
. O

Bert B-MethodName
: O
Pre O
- O
training O
of O
deep O
bidirectional O
transformers O
for O
language O
understanding O
. O

arXiv O
preprint O
arXiv:1810.04805 O
.Ward O

Edwards O
. O

1954 O
. O

The O
theory O
of O
decision O
making O
. O

Psychological O
bulletin O
, O
51(4):380 O
. O

Po O
- O
Sen O
Huang O
, O
Huan O
Zhang O
, O
Ray O
Jiang O
, O
Robert B-MethodName
Stanforth O
, O
Johannes O
Welbl O
, O
Jack O
Rae O
, O
Vishal O
Maini O
, O
Dani O
Yogatama O
, O
and O
Pushmeet O
Kohli O
. O

2019 O
. O

Reducing O
sentiment O
bias O
in O
language O
models O
via O
counterfactual O
evaluation O
. O

arXiv O
preprint O
arXiv:1911.03064 O
. O

David O
Leslie O
. O

2019 O
. O

Human O
compatible O
: O
ArtiÔ¨Åcial O
intelligence O
and O
the O
problem O
of O
control O
. O

Yinhan O
Liu O
, O
Myle O
Ott O
, O
Naman O
Goyal O
, O
Jingfei O
Du O
, O
Mandar O
Joshi O
, O
Danqi O
Chen O
, O
Omer O
Levy O
, O
Mike O
Lewis O
, O
Luke O
Zettlemoyer O
, O
and O
Veselin O
Stoyanov O
. O

2019 O
. O

Roberta B-MethodName
: O
A O
robustly O
optimized O
bert B-MethodName
pretraining O
approach O
. O

arXiv O
preprint O
arXiv:1907.11692 O
. O

Bill O
MacCartney O
. O

2009 O
. O

Natural B-TaskName
language I-TaskName
inference I-TaskName
. O

Citeseer O
. O

Moin O
Nadeem O
, O
Anna O
Bethke O
, O
and O
Siva O
Reddy O
. O
2020 O
. O

Stereoset O
: O
Measuring O
stereotypical O
bias O
in O
pretrained O
language O
models O
. O

arXiv O
preprint O
arXiv:2004.09456 O
. O

Joshua O
Peterson O
, O
David O
Bourgin O
, O
Daniel O
Reichman O
, O
Thomas O
GrifÔ¨Åths O
, O
and O
Stuart O
Russell O
. O

2019 O
. O

Cognitive O
model O
priors O
for O
predicting B-TaskName
human I-TaskName
decisions I-TaskName
. O

InInternational O
Conference O
on O
Machine O
Learning O
, O
pages O
5133‚Äì5141 O
. O

Ori O
Plonsky O
, O
Reut O
Apel O
, O
Eyal O
Ert O
, O
Moshe O
Tennenholtz O
, O
David O
Bourgin O
, O
Joshua O
C O
Peterson O
, O
Daniel O
Reichman O
, O
Thomas O
L O
GrifÔ¨Åths O
, O
Stuart O
J O
Russell O
, O
Evan O
C O
Carter O
, O
et O
al O
. O
2019 O
. O

Predicting B-TaskName
human I-TaskName
decisions I-TaskName
with O
behavioral O
theories O
and O
machine O
learning O
. O

arXiv O
preprint O
arXiv:1904.06866 O
. O

Ariel O
Rosenfeld O
and O
Sarit O
Kraus O
. O

2018 O
. O

Predicting B-TaskName
human I-TaskName
decision I-TaskName
- O
making O
: O
From O
prediction O
to O
action O
. O

Synthesis O
Lectures O
on O
ArtiÔ¨Åcial O
Intelligence O
and O
Machine O
Learning O
, O
12(1):1‚Äì150 O
. O

Stuart O
J O
Russell O
and O
Peter O
Norvig O
. O

2016 O
. O

ArtiÔ¨Åcial O
intelligence O
: O
a O
modern O
approach O
. O

Malaysia O
; O
Pearson B-MetricName
Education O
Limited O
, O
. O

Maarten O
Sap O
, O
Hannah O
Rashkin O
, O
Derek O
Chen O
, O
Ronan O
LeBras O
, O
and O
Yejin O
Choi O
. O

2019 O
. O

Socialiqa O
: O
Commonsense O
reasoning O
about O
social O
interactions O
. O

arXiv O
preprint O
arXiv:1904.09728 O
. O

Alex O
Wang O
, O
Amanpreet O
Singh O
, O
Julian O
Michael O
, O
Felix O
Hill O
, O
Omer O
Levy O
, O
and O
Samuel O
R O
Bowman O
. O

2018 O
. O

Glue O
: O
A O
multi O
- O
task O
benchmark O
and O
analysis O
platform O
for O
natural B-TaskName
language I-TaskName
understanding I-TaskName
. O

arXiv O
preprint O
arXiv:1804.07461 O
. O

Zhilin O
Yang O
, O
Zihang O
Dai O
, O
Yiming O
Yang O
, O
Jaime O
Carbonell O
, O
Ruslan O
Salakhutdinov O
, O
and O
Quoc O
V O
Le O
. O
2019 O
. O

Xlnet B-MethodName
: O

Generalized O
autoregressive O
pretraining O
for O
language O
understanding O
. O

arXiv O
preprint O
arXiv:1906.08237 O
.Rowan O

Zellers O
, O
Yonatan O
Bisk O
, O
Roy O
Schwartz O
, O
and O
Yejin O
Choi O
. O

2018 O
. O

Swag O
: O
A O
large O
- O
scale O
adversarial O
dataset O
for O
grounded O
commonsense O
inference O
. O

arXiv O
preprint O
arXiv:1808.05326 O
. O

