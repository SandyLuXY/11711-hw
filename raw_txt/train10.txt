Proceedings O
of O
the O
58th O
Annual O
Meeting O
of O
the O
Association O
for O
Computational O
Linguistics O
, O
pages O
351‚Äì357 O
July O
5 O
- O
10 O
, O
2020 O
. O

c O

 O
2020 O
Association O
for O
Computational O
Linguistics351Text O
ClassiÔ¨Åcation O
with O
Negative O
Supervision O
Sora O
Ohashiy O
, O
Junya O
Takayamay O
, O
Tomoyuki O
Kajiwaraz O
, O
Chenhui O
Chuz O
, O
Yuki O
Arasey O
yGraduete O
School O
of O
Information O
Science O
and O
Technology O
, O
Osaka O
University O
zInstitute O
of O
Datability O
Science O
, O
Osaka O
University O
yfohashi.sora O
, O
takayama.junya O
, O
arase O
g@ist.osaka-u.ac.jp O
zfkajiwara O
, O
chu O
g@ids.osaka-u.ac.jp O
Abstract O
Advanced O
pre O
- O
trained O
models O
for O
text O
representation O
have O
achieved O
state O
- O
of O
- O
the O
- O
art O
performance O
on O
various O
text O
classiÔ¨Åcation O
tasks O
. O

However O
, O
the O
discrepancy O
between O
the O
semantic O
similarity O
of O
texts O
and O
labelling O
standards O
affects O
classiÔ¨Åers O
, O
i.e.leading O
to O
lower O
performance O
in O
cases O
where O
classiÔ¨Åers O
should O
assign O
different O
labels O
to O
semantically O
similar O
texts O
. O

To O
address O
this O
problem O
, O
we O
propose O
a O
simple O
multitask O
learning O
model O
that O
uses O
negative O
supervision O
. O

SpeciÔ¨Åcally O
, O
our O
model O
encourages O
texts O
with O
different O
labels O
to O
have O
distinct O
representations O
. O

Comprehensive O
experiments O
show O
that O
our O
model O
outperforms O
the O
stateof O
- O
the O
- O
art O
pre O
- O
trained O
model O
on O
both O
singleand O
multi O
- O
label O
classiÔ¨Åcations O
, O
sentence O
and O
document O
classiÔ¨Åcations O
, O
and O
classiÔ¨Åcations O
in O
three O
different O
languages O
. O

1 O
Introduction O
Text O
classiÔ¨Åcation O
generally O
consists O
of O
two O
processes O
: O
an O
encoder O
that O
converts O
texts O
to O
numerical O
representations O
and O
a O
classiÔ¨Åer O
that O
estimates O
hidden O
relations O
between O
the O
representations O
and O
class O
labels O
. O

The O
text O
representations O
are O
generated O
usingN O
- O
gram O
statistics O
( O
Wang O
and O
Manning O
, O
2012 O
) O
, O
word O
embeddings O
( O
Joulin O
et O
al O
. O
, O
2017 O
; O
Wang O
et O
al O
. O
, O
2018 O
) O
, O
convolutional O
neural O
networks O
( O
Kalchbrenner O
et O

al O
. O
, O
2014 O
; O
Zhang O
et O
al O
. O
, O
2015 O
; O
Shen O
et O
al O
. O
, O
2018 O
) O
, O
and O
recurrent O
neural O
networks O
( O
Yang O
et O

al O
. O
, O
2016 O
, O
2018 O
) O

. O

Recently O
, O
powerful O
pre O
- O
trained O
models O
for O
text O
representations O
, O
e.g. O
Bidirectional O
Encoder O
Representations O
from O
Transformers O
( O
BERT O
) O
( O
Devlin O
et O
al O
. O
, O
2019 O
) O
, O
have O
shown O
stateof O
- O
the O
- O
art O
performance O
on O
text O
classiÔ¨Åcation O
tasks O
using O
only O
the O
simple O
classiÔ¨Åer O
of O
a O
fully O
connected O
layer O
. O

However O
, O
a O
problem O
occurs O
when O
a O
classiÔ¨Åcation O
task O
is O
adversarial O
to O
text O
encoders O
. O

Encoders O
aim O
to O
represent O
the O
meanings O
of O
texts O
; O
hence O
, O
seman O
- O
Sentence O
Label O
BERT B-MethodName
A O
cold O
is O
a O
legit O
disease O
. O

‚Äì O
Cold O
Oh O
my O
god O
! O

I O
caught O
a O
cold O
! O

Both O
sentences O
are O
about O
the O
common O
cold O
. O

Only O
the O
second O
example O
indicates O
that O
the O
writer O
had O
a O
cold O
. O

BERT B-MethodName
misclassiÔ¨Åed O
the O
Ô¨Årst O
sentence O
. O

tically O
similar O
texts O
tend O
to O
have O
closer O
representations O
. O

Meanwhile O
, O
a O
classiÔ¨Åer O
should O
distinguish O
subtle O
differences O
that O
lead O
to O
different O
label O
assignments O
, O
although O
the O
texts O
are O
semantically O
similar O
. O

Table O
1 O
shows O
an O
example O
of O
classiÔ¨Åcation O
results O
using O
BERT B-MethodName
for O
the O
MedWeb B-DatasetName
dataset O
( O
Wakamiya O
et O
al O
. O
, O
2017 O
) O
. O

This O
task O
requires O
the O
labelling O
of O
a O
disease O
contracted O
by O
the O
writer O
of O
a O
text O
. O

Although O
both O
texts O
in O
Table O
1 O
refer O
to O
the O
common O
cold O
, O
only O
the O
second O
example O
implies O
that O
the O
writer O
had O
a O
cold O
. O

BERT B-MethodName
mistakenly O
labelled O
both O
texts O
asCold1 O
, O
likely O
owing O
to O
their O
semantic O
relatedness O
. O

When O
the O
standard O
of O
class O
label O
assignments O
disagrees O
with O
the O
semantic O
similarity O
, O
the O
classiÔ¨Åer O
tends O
to O
be O
error O
- O
prone O
owing O
to O
the O
excessive O
effects O
of O
the O
semantic O
similarity O
. O

To O
address O
this O
problem O
, O
we O
propose O
utilizing O
negative O
examples O
, O
i.e.texts O
with O
different O
labels O
, O
to O
enable O
negative O
supervision O
of O
the O
encoder O
for O
generating O
distinct O
representations O
for O
each O
class O
. O

In O
this O
study O
, O
we O
design O
a O
simple O
multitask O
learning O
model O
that O
trains O
two O
models O
simultaneously O
with O
a O
shared O
text O
encoder O
. O

The O
Ô¨Årst O
model O
learns O
an O
ordinary O
classiÔ¨Åcation O
task O
( O
herein O
referred O
to O
as O
the O
main O
task O
) O
. O

Meanwhile O
, O
the O
second O
model O
encourages O
representations O
with O
different O
class O
labels O
to O
be O
distinct O
( O
herein O
referred O
to O
as O
the O
auxiliary O
1We O
use O
the O
typewriter O
font O
to O
indicate O
a O
class O
label O
throughout O
this O
paper.352 O
EncoderI O
caught O
a O
cold O
. O

A O
cold O
is O
a O
legit O
diseaseI‚Äôm O
coughingClassifierDiscriminatorColdMain O
TaskAuxiliary O
TaskFigure O
1 O
: O
Our O
model O
consists O
of O
a O
classiÔ¨Åer O
, O
discriminator O
, O
and O
shared O
text O
encoder O
. O

The O
main O
task O
learns O
classiÔ¨Åcation O
, O
while O
the O
auxiliary O
task O
gives O
negative O
supervision O
to O
generate O
distinct O
representations O
for O
sentences O
with O
different O
labels O
. O
task O
) O
. O

We O
empirically O
show O
the O
effectiveness O
of O
our O
model O
using O
the O
following O
standard O
benchmarks O
of O
Ô¨Åve O
single O
- O
label O
and O
four O
multi O
- O
label O
classiÔ¨Åcation O
datasets O
. O

This O
study O
has O
two O
main O
contributions O
. O

Our O
multi O
- O
tasking O
learning O
model O
consistently O
outperforms O
the O
state O
- O
of O
- O
the O
- O
art O
model O
in O
terms O
of O
both O
single O
and O
multi O
- O
label O
classiÔ¨Åcations O
, O
sentence O
and O
document O
classiÔ¨Åcations O
, O
and O
classiÔ¨Åcations O
in O
three O
languages O
. O

Our O
model O
is O
simple O
and O
easily O
applicable O
to O
any O
text O
encoders O
and O
classiÔ¨Åers O
. O

2 O
Multitask O
Learning O
Framework O
Figure O
1 O
shows O
an O
overview O
of O
our O
multitask O
learning O
framework O
that O
consists O
of O
main O
and O
auxiliary O
tasks O
. O

Herein O
, O
we O
refer O
to O
the O
model O
for O
the O
main O
task O
as O
a O
classiÔ¨Åer O
and O
the O
model O
for O
the O
auxiliary O
task O
as O
a O
discriminator O
. O

The O
overall O
loss O
function O
L O
sums O
the O
loss O
of O
the O
main O
task O
Lmand O
that O
of O
the O
auxiliary O
taskLa O
: O
L O
= O
Lm+La O
: O
The O
classiÔ¨Åer O
and O
discriminator O
share O
and O
jointly O
optimize O
the O
text O
encoder O
, O
which O
encodes O
an O
input O
text O
into O
ad O
- O
dimensional O
vector O
v2Rd O
. O

In O
this O
paper O
, O
we O
use O
the O
terms O
of O
text O
and O
representation O
interchangeably O
when O
the O
intention O
is O
obvious O
from O
the O
context.2.1 O
Main O
Task O
The O
main O
task O
is O
the O
primary O
classiÔ¨Åcation O
task O
to O
optimize O
. O

We O
use O
a O
simple O
classiÔ¨Åer O
as O
employed O
in O
BERT B-MethodName
. O

The O
classiÔ¨Åer O
takes O
an O
input O
vector O
vm O
and O
calculates O
probabilities O
p2RjCjto O
assign O
a O
set O
of O
class O
labels O
C O
: O
p O
= O
g(Wvm+b O
) O
; O
where O
W2RjCjdandb2RjCjare O
parameters O
of O
the O
classiÔ¨Åer O
, O
in O
which O
jjcounts O
the O
number O
of O
elements O
in O
a O
set O
. O

Forg O
, O
we O
employ O
a O
softmax O
function O
for O
singlelabel O
classiÔ¨Åcation O
and O
a O
sigmoid O
function O
for O
multilabel O
classiÔ¨Åcation O
. O

In O
both O
cases O
, O
Lmis O
a O
negative O
log O
- O
likelihood O
of O
predictions O
. O

2.2 O
Auxiliary O
Task O
The O
auxiliary O
task O
aims O
to O
give O
negative O
supervision O
to O
encourage O
distinct O
representations O
of O
texts O
with O
different O
labels O
. O

The O
discriminator O
samples O
a O
set O
of O
ntextsva O
1;:::;va O
nfrom O
the O
same O
batch O
as O
vm O
, O
all O
of O
which O
have O
different O
labels O
from O
vm O
. O

To O
encourage O
these O
texts O
to O
have O
distinct O
representations O
, O
we O
designed O
the O
loss O
function O
Laas O
La=1 O
nX O
ism O
i O
; O
sm O
j= O
1 O
+ O
cossim O
( O
vm;va O
j O
) O
; O
where O
the O
cossim O
function O
computes O
the O
cosine O
similarity O
between O
the O
representations O
. O

This O
loss O
function O
intuitively O
encourages O
the O
negative O
examples O
to O
have O
smaller O
cosine O
similarities O
. O

3 O
Experiments O
We O
conducted O
a O
comprehensive O
evaluation O
to O
investigate O
the O
performance O
of O
our O
model O
in O
terms O
of O
( O
a O
) O
single- O
and O
multi O
- O
label O
classiÔ¨Åcations O
, O
( O
b O
) O
sentence- O
and O
document O
- O
level O
classiÔ¨Åcation O
, O
and O
( O
c O
) O
different O
languages O
. O

We O
collected O
the O
standard O
evaluation O
datasets O
from O
heterogeneous O
sources O
, O
as O
summarised O
in O
Table O
2 O
. O
3.1 O
Single O
- O
Label O
ClassiÔ¨Åcation O
As O
datasets O
assigned O
single O
labels O
to O
sentences O
, O
we O
used O
the O
following O
datasets O
from O
the O
SentEval B-DatasetName
( O
Conneau O
and O
Kiela O
, O
2018)2benchmark O
. O

MR B-DatasetName
Binary O
classiÔ¨Åcation O
of O
sentiment O
polarity O
of O
movie O
reviews O
. O

2https://github.com/facebookresearch/SentEval353Input O

The O
upper O
group O
is O
single O
- O
label O
classiÔ¨Åcation O
tasks O
, O
whereas O
the O
bottom O
group O
is O
multi O
- O
label O
classiÔ¨Åcation O
tasks O
. O

CR B-DatasetName
Binary O
classiÔ¨Åcation O
of O
sentiment O
polarity O
of O
product O
reviews O
. O

SST-5 B-DatasetName
Multi O
- O
class O
classiÔ¨Åcation O
of O
the O
Ô¨Ånegrained O
sentiment O
polarity O
of O
movie O
reviews O
. O

Labels O
are O
Positive O
, O
Somewhat O
Positive O
, O
Neutral O
, O
Somewhat O
Negative O
, O
andNegative O
. O

TREC B-DatasetName
Multi O
- O
class O
classiÔ¨Åcation O
of O
question O
types.3 O
SUBJ B-DatasetName
Binary O
classiÔ¨Åcation O
of O
subjectivity O
. O

Because O
the O
MR B-DatasetName
, O
CR B-DatasetName
, O
and O
SUBJ B-DatasetName
datasets O
do O
not O
separate O
validation O
and O
test O
sets O
, O
we O
split O
20 O
% O
of O
each O
dataset O
for O
testing O
and O
20 O
% O
of O
the O
remainder O
for O
validation O
. O

The O
evaluation O
metric O
for O
these O
single B-MetricName
- I-MetricName
label I-MetricName
classiÔ¨Åcation I-MetricName
tasks O
is O
accuracy B-MetricName
. O

3.2 O
Multi B-MetricName
- I-MetricName
Label I-MetricName
ClassiÔ¨Åcation I-MetricName
We O
used O
the O
NTCIR-13 B-DatasetName
MedWeb I-DatasetName
( O
Wakamiya O
et O
al O
. O
, O
2017 O
) O
and O
arXiv B-DatasetName
datasets O
( O
Yang O
et O
al O
. O
, O
2018 O
) O
for O
multi B-MetricName
- I-MetricName
label I-MetricName
classiÔ¨Åcation I-MetricName
. O

MedWeb B-DatasetName
Assigning O
disease O
labels O
that O
a O
writer O
of O
a O
sentence O
contracted.4 O
arXiv B-DatasetName
ClassiÔ¨Åcation O
of O
areas O
of O
abstracts O
extracted O
from O
papers O
in O
the O
computer O
science O
Ô¨Åeld.5 O
Because O
the O
arXiv B-DatasetName
dataset O
released O
by O
Yang O
et O

al O
. O
( O
2018 O
) O
removed O
all O
line O
breaks O
, O
we O
created O
one O
ourselves O
. O

We O
collected O
abstracts O
and O
categories O
of O
papers O
submitted O
to O
arXiv O
from O
January O
1st O
, O
2019 O
to O
June O
4th O
, O
2019 O
using O
arXiv O
API.6 O
3All O
question O
types O
are O
in O
the O
appendix O
. O

4http://research.nii.ac.jp/ntcir/permission/ntcir-13/permja-MedWeb.html O
5The O
labels O
of O
these O
two O
tasks O
are O
in O
the O
appendix O
. O

6https://arxiv.org/help/apiThe O
evaluation O
metric O
for O
multi B-MetricName
- I-MetricName
label I-MetricName
classiÔ¨Åcation I-MetricName
is O
Exact B-MetricName
- I-MetricName
Match I-MetricName
. O

ExactMatch B-MetricName
= O
1 O
MMX O
i=1I(yi=^yi O
) O
; O
whereyiand^yiare O
one O
- O
hot O
vectors O
of O
gold O
and O
predicted O
labels O
, O
respectively O
, O
and O
I(x)takes O
1when O
xis O
true O
and O
takes O
0otherwise O
. O

Mis O
the O
size O
of O
a O
test O
set O
. O

3.3 O
Settings O
As O
a O
text O
encoder O
, O
we O
employed O
BERT B-MethodName
and O
a O
Hierarchical B-MethodName
Attention I-MethodName
Network I-MethodName
( O
HAN B-MethodName
) O
( O
Yang O
et O
al O
. O
, O
2016 O
) O
for O
generating O
sentence O
and O
document O
representation O
, O
respectively O
. O

For O
BERT B-MethodName
, O
we O
used O
the O
pre O
- O
trained O
BERT B-MethodName
- O
base7(d= O
768 B-HyperparameterValue
) O
. O

We O
implemented O
the O
HAN O
following O
Yang O
et O
al O
. O

( O
2016 O
) O
who O
used O
the O
bi O
- O
directional O
Gated O
Recurrent O
Unit O
as O
the O
encoder O
with O
the O
hidden B-HyperparameterName
size I-HyperparameterName
of O
50 B-HyperparameterValue
(d= O
50 B-HyperparameterValue
) O
. O

The O
embedding O
layer O
of O
the O
HAN O
was O
initialised O
using O
CBOW O
( O
Mikolov O
et O
al O
. O
, O
2013 O
) O
embeddings O
( O
with O
dimensions B-HyperparameterName
of O
200 B-HyperparameterValue
) O
, O
which O
were O
trained O
using O
negative O
sampling O
on O
the O
training O
and O
development O
sets O
of O
each O
task O
. O

For O
systematic O
comparison O
, O
we O
investigated O
the O
performance O
of O
the O
following O
models O
. O

As O
a O
baseline O
, O
we O
compared O
models O
that O
conduct O
only O
the O
main O
task O
( O
referred O
to O
as O
Baseline O
) O
, O
which O
corresponds O
to O
the O
Ô¨Åne O
- O
tuned O
BERT B-MethodName
- I-MethodName
base I-MethodName
for O
sentence B-MetricName
classiÔ¨Åcation I-MetricName
and O
the O
original O
HAN B-MethodName
for O
document B-MetricName
classiÔ¨Åcation I-MetricName
. O

Note O
that O
this O
BERT B-MethodName
baseline O
signiÔ¨Åcantly O
outperforms O
previous O
state O
- O
of O
- O
the O
- O
art O
methods O
, O
which O
were O
also O
compared O
in O
the O
experiment O
. O

To O
investigate O
the O
effects O
of O
negative O
supervision O
at O
7https://github.com/google-research/bert354 O
MR B-DatasetName
CR B-DatasetName
SST-5 B-DatasetName
TREC B-DatasetName

SUBJ B-DatasetName
MedWeb B-DatasetName
arXiv B-DatasetName

The O
best O
scores O
are O
presented O
in O
the O
bold O
font O
, O
and O
scores O
higher O
than O
the O
Baseline O
are O
underlined O
. O

Our O
models O
consistently O
outperform O
the O
baseline O
and O
ACE B-MethodName
, O
which O
indicates O
the O
effectiveness O
of O
negative O
supervision O
through O
the O
auxiliary O
task O
. O

Previous O
SOTA O
results O
are O
reported O
by O
Du O
et O
al O
. O

( O
2019 O
) O
( O
MR B-DatasetName
) O
, O

Zhou O
et O

al O
. O

( O
2016 O
) O
( O
CR B-DatasetName
, O
SST-5 B-DatasetName
) O
, O
Howard O
and O
Ruder O
( O
2018 O
) O
( O
TREC B-DatasetName
) O
, O

Zhao O
et O
al O
. O
( O
2015 O
) O
( O
SUBJ B-DatasetName
) O
and O
Iso O
et O

al O
. O

( O
2017 O
) O
( O
MedWeb B-DatasetName
) O
. O

the O
auxiliary O
task O
, O
we O
compared O
our O
model O
to O
one O
that O
predicts O
a O
sentence O
with O
the O
same O
label O
. O

Accurately O
, O
this O
model O
conducts O
classiÔ¨Åcation O
given O
cosine O
similarities O
using O
cross O
entropy O
loss O
( O
referred O
to O
as O
ACE B-MethodName
( O
the O
auxiliary B-MethodName
task I-MethodName
with I-MethodName
cross I-MethodName
entropy I-MethodName
loss I-MethodName
) O
) O
. O

Furthermore O
, O
we O
evaluated O
two O
variations O
of O
our O
model O
. O

The O
Ô¨Årst O
purely O
gives O
negative O
supervision O
, O
i.e. O
, O
the O
auxiliary O
task O
only O
encourages O
the O
generation O
of O
distinct O
representation O
to O
negative O
examples O
, O
as O
described O
in O
Section O
2.2 O
( O
referred O
to O
as O
AAN B-MethodName
( O
the O
auxiliary B-MethodName
task I-MethodName
using I-MethodName
all I-MethodName
negative I-MethodName
examples I-MethodName
) O
) O
. O

The O
second O
uses O
the O
following O
margin O
- O
based O
loss O
asLawith O
a O
positive O
example O
as O
well O
as O
negative O
examples O
: O
La= O
max0 O
@0; sm O
k+1 O
n 1X O
i6 O
= O
ksm O
i1 O
A O
; O
where O
thek O
- O
th O
sample O
is O
selected O
to O
have O
the O
same O
label O
as O
the O
input O
vmto O
the O
main O
task O
and O
is O
the O
margin B-HyperparameterName
empirically O
set O
to O
0.4 B-HyperparameterValue
(referred O
to O
as O
AM B-MethodName
( O
the O
auxiliary B-MethodName
task I-MethodName
with I-MethodName
the I-MethodName
margin I-MethodName
- I-MethodName
based I-MethodName
loss I-MethodName
) O
) O
. O

The O
intuition O
is O
that O
texts O
with O
the O
same O
label O
should O
have O
more O
similar O
representations O
than O
negative O
examples O
. O

We O
set O
the O
batch B-HyperparameterName
size I-HyperparameterName
of O
the O
main O
task O
to O
16 B-HyperparameterValue
and O
set O
n B-HyperparameterName
to O
four B-HyperparameterValue
in O
the O
auxiliary O
task O
, O
which O
performed O
best O
on O
the O
validation O
set O
of O
the O
MR B-DatasetName
task O
. O

We O
used O
early O
stopping O
to O
cease O
training O
when O
the O
validation O
score O
did O
not O
improve O
for O
10 B-HyperparameterValue
epochs O
. O

The O
optimization B-HyperparameterName
algorithm I-HyperparameterName
used O
was O
Adam O
( O
Kingma O
and O
Ba O
, O
2015 O
) O
with O
 O
1= O
0.999 B-HyperparameterValue
and O
 O
2= O
0.9 B-HyperparameterValue
. O

For O
each O
task O
, O
we O
selected O
the O
best O
learning B-HyperparameterName
rate I-HyperparameterName
among O
1e-5 B-HyperparameterValue
, O
3e-5 B-HyperparameterValue
, O
and O
5e-5 B-HyperparameterValue
using O
the O
validation O
set O
. O

To O
alleviate O
randomness O
owing O
to O
initialization O
, O
wereported O
average O
scores O
of O
10time O
trials O
excluding O
the O
best O
and O
worst O
results O
. O

3.4 O
Results O
Table O
3 O
shows O
the O
performance O
of O
all O
compared O
methods O
as O
well O
as O
the O
performance O
of O
the O
previous O
state O
- O
of O
- O
the O
- O
art O
methods O
( O
referred O
to O
as O
SOTA O
) O
. O

The O
results O
in O
Table O
3 O
indicate O
that O
our O
models O
of O
AM B-MethodName
and O
AAN B-MethodName
consistently O
outperform O
the O
strong O
Baselines O
on O
both O
single B-MetricName
- I-MetricName
label I-MetricName
and O
multi B-MetricName
- I-MetricName
label I-MetricName
classiÔ¨Åcations I-MetricName
, O
sentence B-MetricName
and I-MetricName
document I-MetricName
classiÔ¨Åcations I-MetricName
, O
and O
classiÔ¨Åcations B-MetricName
in I-MetricName
different I-MetricName
languages I-MetricName
. O

Most O
notably O
, O
our O
models O
are O
effective O
even O
for O
multi B-MetricName
- I-MetricName
label I-MetricName
classiÔ¨Åcation I-MetricName
, O
which O
is O
more O
challenging O
than O
its O
single O
- O
label O
counterpart O
. O

In O
general O
, O
AAN B-MethodName
achieved O
greater O
performance O
than O
AM B-MethodName
. O

However O
, O
their O
effectiveness O
turned O
out O
to O
be O
task O
- O
dependent O
. O

Unlike O
AM B-MethodName
and O
AAN B-MethodName
, O
ACE B-MethodName
degraded O
the O
performance O
of O
the O
Baseline O
except O
for O
the O
MedWeb B-DatasetName
Japanese O
task O
. O

This O
result O
shows O
that O
simple O
multitask O
learning O
is O
ineffective O
and O
that O
our O
design O
using O
negative O
supervision O
is O
crucial O
. O

SST-5 B-DatasetName
is O
an O
exception O
wherein O
our O
models O
degraded O
the O
performance O
of O
the O
Baseline O
. O

We O
hypothesise O
that O
this O
is O
because O
its O
class O
labels O
are O
gradational O
, O
e.g. O
Somewhat O
Negative O
is O
closer O
toNegative O
rather O
than O
Positive O
sentences O
. O

AM B-MethodName
and O
AAN B-MethodName
treat O
all O
negative O
examples O
equally O
, O
disregarding O
variables O
, O
such O
as O
relations O
between O
class O
labels O
. O

Future O
work O
should O
focus O
on O
the O
semantic O
relations O
among O
class O
labels O
in O
the O
auxiliary O
task O
. O

4 O
Related O
Work O
Multitask O
learning O
has O
been O
employed O
to O
improve O
the O
performance O
of O
text B-MetricName
classiÔ¨Åcation I-MetricName
( O
Liu O
et O
al O
. O
,3552019 O
; O
Xiao O
et O
al O
. O
, O
2018 O
) O
. O

Previous O
studies O
aimed O
to O
improve O
multiple O
tasks O
; O
hence O
, O
they O
required O
multiple O
sets O
of O
annotated O
datasets O
. O

In O
contrast O
, O
our O
method O
does O
not O
require O
any O
extra O
labelled O
datasets O
and O
is O
easily O
applicable O
to O
various O
classiÔ¨Åcation O
tasks O
. O

The O
methods O
proposed O
in O
Arase O
and O
Tsujii O
( O
2019 O
) O
and O
Phang O
et O
al O
. O

( O
2018 O
) O
improved O
the O
BERT B-MethodName
classiÔ¨Åcation O
performance O
by O
further O
training O
the O
pre O
- O
trained O
model O
using O
natural O
language O
inference O
and O
paraphrase O
recognition O
. O

Similar O
to O
multitask O
learning O
, O
both O
methods O
require O
an O
additional O
largescale O
labelled O
dataset O
. O

Furthermore O
, O
these O
previous O
studies O
revealed O
that O
the O
similarity O
of O
tasks O
in O
training O
affects O
the O
models O
‚Äô O
Ô¨Ånal O
performance O
( O
Xiao O
et O
al O
. O
, O
2018 O
; O
Arase O
and O
Tsujii O
, O
2019 O
) O
. O

Our O
method O
achieved O
consistent O
improvements O
across O
tasks O
, O
indicating O
its O
wider O
applicability O
. O

5 O
Conclusion O
In O
this O
paper O
, O
we O
proposed O
a O
simple O
multitask O
learning O
model O
that O
uses O
negative O
supervision O
to O
generate O
distinct O
representations O
for O
texts O
with O
different O
labels O
. O

Comprehensive O
evaluation O
empirically O
conÔ¨Årmed O
that O
our O
model O
consistently O
outperformed O
BERT B-MethodName
and O
HAN B-MethodName
models O
on O
single- B-MetricName
and I-MetricName
multi I-MetricName
- I-MetricName
label I-MetricName
classiÔ¨Åcations I-MetricName
, O
sentence B-MetricName
and I-MetricName
document I-MetricName
classiÔ¨Åcations I-MetricName
, O
and O
classiÔ¨Åcations B-MetricName
in I-MetricName
different I-MetricName
languages I-MetricName
. O

Our O
multitask O
learning O
model O
provides O
a O
general O
framework O
that O
is O
easily O
applicable O
to O
existing O
text B-MetricName
classiÔ¨Åcation I-MetricName
models O
. O

In O
future O
work O
, O
we O
will O
examine O
semantic O
relations O
between O
class O
labels O
in O
the O
auxiliary O
task O
. O

Moreover O
, O
we O
will O
adapt O
our O
model O
to O
text O
generation O
tasks O
. O

We O
expect O
that O
our O
model O
will O
encourage O
a O
generation O
model O
to O
generate O
texts O
with O
different O
labels O
, O
such O
as O
styles O
, O
have O
distinct O
representations O
, O
which O
will O
result O
in O
class O
speciÔ¨Åc O
expressions O
. O

Acknowledgement O
This O
work O
was O
supported O
by O
JST O
AIP O
- O
PRISM O
Grant O
Number O
JPMJCR18Y1 O
, O
Japan O
. O
