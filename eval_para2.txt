Analyzing	O
deep	O
NLP	O
models	O
-There	O
has	O
been	O
substantial	O
work	O
in	O
gaining	O
better	O
understanding	O
of	O
complex	O
,	O
deep	O
neural	O
NLP	O
models	O
.	O
By	O
visualizing	O
dense	O
hidden	O
vectors	O
,	O
Li	O
et	O
al	O
.	O
(	O
2016	O
)	O
found	O
that	O
some	O
dimensions	O
of	O
the	O
final	O
representation	O
learned	O
by	O
recurrent	O
neural	O
networks	O
capture	O
the	O
effect	O
of	O
intensification	O
and	O
negation	O
in	O
the	O
input	O
text	O
.	O
Karpathy	O
et	O
al	O
.	O
(	O
2015	O
)	O
revealed	O
the	O
existence	O
of	O
interpretable	O
cells	O
in	O
a	O
character	O
-	O
level	O
LSTM	O
model	O
for	O
language	O
modelling	O
.	O
For	O
example	O
,	O
they	O
found	O
a	O
cell	O
acting	O
as	O
a	O
line	O
length	O
counter	O
and	O
cells	O
checking	O
if	O
the	O
current	O
letter	O
is	O
inside	O
a	O
parenthesis	O
or	O
a	O
quote	O
.	O
Jacovi	O
et	O
al	O
.	O
(	O
2018	O
)	O
presented	O
interesting	O
findings	O
about	O
CNNs	O
for	O
text	O
classification	O
including	O
the	O
fact	O
that	O
one	O
convolutional	O
filter	O
may	O
detect	O
more	O
than	O
one	O
n	O
-	O
gram	O
pattern	O
and	O
may	O
also	O
suppress	O
negative	O
n	O
-	O
grams	O
.	O
Many	O
recent	O
papers	O
studied	O
several	O
types	O
of	O
knowledge	O
in	O
BERT	O
(	O
Devlin	O
et	O
al	O
.	O
,	O
2019	O
)	O
,	O
a	O
deep	O
transformer	O
-	O
based	O
model	O
for	O
language	O
understanding	O
,	O
and	O
found	O
that	O
syntactic	O
information	O
is	O
mostly	O
captured	O
in	O
the	O
middle	O
BERT	O
layers	O
while	O
the	O
final	O
BERT	O
layers	O
are	O
the	O
most	O
task	O
-	O
specific	O
(	O
Rogers	O
et	O
al	O
.	O
,	O
2020	O
)	O
.	O
Inspired	O
by	O
many	O
findings	O
,	O
we	O
make	O
the	O
assumption	O
that	O
each	O
dimension	O
of	O
the	O
final	O
representation	O
(	O
i.e.	O
,	O
the	O
vector	O
before	O
the	O
output	O
layer	O
)	O
captures	O
patterns	O
or	O
qualities	O
in	O
the	O
input	O
which	O
are	O
useful	O
for	O
classification	O
.	O
Therefore	O
,	O
understanding	O
the	O
roles	O
of	O
these	O
dimensions	O
(	O
we	O
refer	O
to	O
them	O
as	O
features	O
)	O
is	O
a	O
prerequisite	O
for	O
effective	O
human	O
-	O
in	O
-	O
the	O
-	O
loop	O
model	O
debugging	O
,	O
and	O
we	O
exploit	O
an	O
explanation	O
method	O
to	O
gain	O
such	O
an	O
understanding	O
.	O
Explaining	O
predictions	O
from	O
text	O
classifiers	O
-Several	O
methods	O
have	O
been	O
devised	O
to	O
generate	O
explanations	O
supporting	O
classifications	O
in	O
many	O
forms	O
,	O
such	O
as	O
natural	O
language	O
texts	O
,	O
rules	O
(	O
Ribeiro	O
et	O
al	O
.	O
,	O
2018	O
)	O
,	O
extracted	O
rationales	O
(	O
Lei	O
et	O
al	O
.	O
,	O
2016	O
)	O
,	O
and	O
attribution	O
scores	O
(	O
Lertvittayakumjorn	O
and	O
Toni	O
,	O
2019	O
)	O
.	O
Some	O
explanation	O
methods	O
,	O
such	O
as	O
LIME	O
(	O
Ribeiro	O
et	O
al	O
.	O
,	O
2016	O
)	O
and	O
SHAP	O
(	O
Lundberg	O
and	O
Lee	O
,	O
2017	O
)	O
,	O
are	O
model	O
-	O
agnostic	O
and	O
do	O
not	O
require	O
access	O
to	O
model	O
parameters	O
.	O
Other	O
methods	O
access	O
the	O
model	O
architectures	O
and	O
parameters	O
to	O
generate	O
the	O
explanations	O
,	O
such	O
as	O
DeepLIFT	O
(	O
Shrikumar	O
et	O
al	O
.	O
,	O
2017	O
)	O
and	O
LRP	O
(	O
layer	O
-	O
wise	O
relevance	O
propagation	O
)	O
(	O
Bach	O
et	O
al	O
.	O
,	O
2015;Arras	O
et	O
al	O
.	O
,	O
2016	O
)	O
.	O
In	O
this	O
work	O
,	O
we	O
use	O
LRP	O
to	O
explain	O
not	O
the	O
predictions	O
but	O
the	O
learned	O
features	O
so	O
as	O
to	O
expose	O
the	O
model	O
behavior	O
to	O
humans	O
and	O
enable	O
informed	O
model	O
debugging	O
.	O
